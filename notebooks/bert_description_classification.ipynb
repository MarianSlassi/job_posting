{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb9e4e60",
   "metadata": {},
   "source": [
    "## Opening"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8548313d",
   "metadata": {},
   "source": [
    "### Modules init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b8348fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current dir for import: C:\\Users\\Мариан\\Desktop\\Jupyter Notes\\Projects\\Trainee_iFortex\\Git\\job_posting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Мариан\\Desktop\\Jupyter Notes\\Projects\\Trainee_iFortex\\Git\\job_posting\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config initialized\n"
     ]
    }
   ],
   "source": [
    "# System/env config\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "parent_dir = Path.cwd().resolve().parent\n",
    "sys.path.append(str(parent_dir))\n",
    "print('Current dir for import:', parent_dir)\n",
    "\n",
    "from src.config import Config\n",
    "config = Config()\n",
    "print('Config initialized')\n",
    "\n",
    "\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Modules for data \n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from datasets import Dataset\n",
    "from datasets import load_from_disk\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoConfig, AutoModelForSequenceClassification,\n",
    "    TrainingArguments, Trainer, EarlyStoppingCallback\n",
    ")\n",
    "\n",
    "import evaluate\n",
    "import torch\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30adbd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temp. Used for fast init and testing\n",
    "with open(os.path.join(os.getcwd(), 'id2label.json'), \"r\", encoding=\"utf-8\") as f:\n",
    "    id2label = json.load(f)\n",
    "with open(os.path.join(os.getcwd(), 'label2id.json'), \"r\", encoding=\"utf-8\") as f:\n",
    "    label2id = json.load(f)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d59bae",
   "metadata": {},
   "source": [
    "### Download ETL Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65dee2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(config.get('cleaned_parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8563882e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>job_posting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Automotive</td>\n",
       "      <td>£500 Bonus on Attandance during Black Friday a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>$2, 500 POTENTIAL RETENTION BONUS! WHAT'S NEW ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Automotive</td>\n",
       "      <td>£500 Bonus on Attandance during Black Friday a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Automotive</td>\n",
       "      <td>£500 Bonus on Attandance during Black Friday a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Government</td>\n",
       "      <td>AS9102 First article &amp; ANSI Y14.5M 1982 \" Basi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1760381</th>\n",
       "      <td>Sales</td>\n",
       "      <td>Structured training and development programmes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1760386</th>\n",
       "      <td>Management</td>\n",
       "      <td>Be responsible for managing impact to people f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1760387</th>\n",
       "      <td>Operations</td>\n",
       "      <td>At Liberty Mutual, technology isn't just a par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1760388</th>\n",
       "      <td>Science</td>\n",
       "      <td>€30k per annum. 12 month contract. Dublin. We ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1760392</th>\n",
       "      <td>Engineering</td>\n",
       "      <td>Are you a Fire Protection Engineer looking for...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>633220 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              category                                        job_posting\n",
       "6           Automotive  £500 Bonus on Attandance during Black Friday a...\n",
       "10       Manufacturing  $2, 500 POTENTIAL RETENTION BONUS! WHAT'S NEW ...\n",
       "17          Automotive  £500 Bonus on Attandance during Black Friday a...\n",
       "18          Automotive  £500 Bonus on Attandance during Black Friday a...\n",
       "20          Government  AS9102 First article & ANSI Y14.5M 1982 \" Basi...\n",
       "...                ...                                                ...\n",
       "1760381          Sales  Structured training and development programmes...\n",
       "1760386     Management  Be responsible for managing impact to people f...\n",
       "1760387     Operations  At Liberty Mutual, technology isn't just a par...\n",
       "1760388        Science  €30k per annum. 12 month contract. Dublin. We ...\n",
       "1760392    Engineering  Are you a Fire Protection Engineer looking for...\n",
       "\n",
       "[633220 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369d2bd4",
   "metadata": {},
   "source": [
    "### Preprocess cleaned data For BERT - numbers and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba0d4c3",
   "metadata": {},
   "source": [
    "For BERT we need to cleand data from uneccessary numbers, and encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9d677f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_for_bert(text: str) -> str:\n",
    "    text = str(text)\n",
    "    text = re.sub(r\"<.*?>\", \" \", text)                     # HTML\n",
    "    text = re.sub(r\"http\\S+|www\\.\\S+\", \" \", text)          # URL\n",
    "    text = re.sub(r\"\\S+@\\S+\", \" \", text)                   # email\n",
    "    text = re.sub(r\"\\+?\\d[\\d\\-\\(\\) ]{7,}\\d\", \" \", text)    # phones\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "assert {\"job_posting\", \"category\"}.issubset(df.columns), df.columns\n",
    "\n",
    "df[\"job_posting\"] = df[\"job_posting\"].apply(clean_for_bert)\n",
    "\n",
    "\n",
    "labels = sorted(df[\"category\"].unique())\n",
    "label2id = {lbl:i for i,lbl in enumerate(labels)}\n",
    "id2label = {i:lbl for lbl,i in label2id.items()}\n",
    "df[\"category\"] = df[\"category\"].map(label2id).astype(int)\n",
    "\n",
    "with open(\"label2id.json\", \"w\") as f: json.dump(label2id, f)\n",
    "with open(\"id2label.json\", \"w\") as f: json.dump(id2label, f)\n",
    "\n",
    "df = df.rename(columns={'job_posting':'text', 'category': 'labels'})\n",
    "df.to_parquet('../data/02_cleaned/bert_train_data.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aefbed",
   "metadata": {},
   "source": [
    "## Tokenization and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe76cb0",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "224b0fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(os.getcwd(), 'id2label.json'), \"r\", encoding=\"utf-8\") as f:\n",
    "    id2label = json.load(f)\n",
    "with open(os.path.join(os.getcwd(), 'label2id.json'), \"r\", encoding=\"utf-8\") as f:\n",
    "    label2id = json.load(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d070969",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('../data/02_cleaned/bert_train_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e62807f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>£500 Bonus on Attandance during Black Friday a...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>$2, 500 POTENTIAL RETENTION BONUS! WHAT'S NEW ...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>£500 Bonus on Attandance during Black Friday a...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>£500 Bonus on Attandance during Black Friday a...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>AS9102 First article &amp; ANSI Y14.5M 1982 \" Basi...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1760381</th>\n",
       "      <td>Structured training and development programmes...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1760386</th>\n",
       "      <td>Be responsible for managing impact to people f...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1760387</th>\n",
       "      <td>At Liberty Mutual, technology isn't just a par...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1760388</th>\n",
       "      <td>€30k per annum. 12 month contract. Dublin. We ...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1760392</th>\n",
       "      <td>Are you a Fire Protection Engineer looking for...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>633115 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  labels\n",
       "6        £500 Bonus on Attandance during Black Friday a...       2\n",
       "10       $2, 500 POTENTIAL RETENTION BONUS! WHAT'S NEW ...      16\n",
       "17       £500 Bonus on Attandance during Black Friday a...       2\n",
       "18       £500 Bonus on Attandance during Black Friday a...       2\n",
       "20       AS9102 First article & ANSI Y14.5M 1982 \" Basi...       9\n",
       "...                                                    ...     ...\n",
       "1760381  Structured training and development programmes...      21\n",
       "1760386  Be responsible for managing impact to people f...      15\n",
       "1760387  At Liberty Mutual, technology isn't just a par...      18\n",
       "1760388  €30k per annum. 12 month contract. Dublin. We ...      22\n",
       "1760392  Are you a Fire Protection Engineer looking for...       7\n",
       "\n",
       "[633115 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0a293e",
   "metadata": {},
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1eb36c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test_df = train_test_split(df[[\"text\", \"labels\"]], test_size=0.05, random_state=42, stratify=df[\"labels\"])\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "    train[[\"text\", \"labels\"]], test_size=0.1, random_state=42, stratify=train[\"labels\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f40b4f",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69e5021",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 541403/541403 [07:19<00:00, 1232.30 examples/s]\n",
      "Map: 100%|██████████| 60156/60156 [00:50<00:00, 1180.56 examples/s]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"distilbert/distilbert-base-uncased\"  \n",
    "max_length = 512       # tokens in sequence             \n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=False\n",
    "    )\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df, preserve_index=False)\n",
    "val_ds   = Dataset.from_pandas(val_df,   preserve_index=False)\n",
    "\n",
    "train_ds = train_ds.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
    "val_ds   = val_ds.map(tokenize,   batched=True, remove_columns=[\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c79d200",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain_ds\u001b[49m.save_to_disk(\u001b[33m\"\u001b[39m\u001b[33m../data/tokenized/train\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m val_ds.save_to_disk(\u001b[33m\"\u001b[39m\u001b[33m../data/tokenized/val\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'train_ds' is not defined"
     ]
    }
   ],
   "source": [
    "train_ds.save_to_disk(\"../data/tokenized/train\")\n",
    "val_ds.save_to_disk(\"../data/tokenized/val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cd1ce3",
   "metadata": {},
   "source": [
    "### Load Tokenized Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e309107",
   "metadata": {},
   "source": [
    "Important that data was tokenized without padding for sequences, we should set Collator later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89a32e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"distilbert/distilbert-base-uncased\"  \n",
    "max_length = 512       # tokens in sequence             \n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "with open(os.path.join(os.getcwd(), 'id2label.json'), \"r\", encoding=\"utf-8\") as f:\n",
    "    id2label = json.load(f)\n",
    "with open(os.path.join(os.getcwd(), 'label2id.json'), \"r\", encoding=\"utf-8\") as f:\n",
    "    label2id = json.load(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a40645f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = load_from_disk(\"../data/tokenized/train\")\n",
    "val_ds   = load_from_disk(\"../data/tokenized/val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a18aa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.set_format(type=\"torch\")\n",
    "val_ds.set_format(type=\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75b2f46",
   "metadata": {},
   "source": [
    "### Arguments and preobject parametrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ca2481e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "574c2368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78d9bd85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d2e157",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=config.get('models_dir'),\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    eval_steps=1000,\n",
    "    save_steps=1000,\n",
    "    logging_steps=200,\n",
    "    per_device_train_batch_size=16,     \n",
    "    per_device_eval_batch_size=16,\n",
    "    gradient_accumulation_steps=2,    \n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.06,\n",
    "    weight_decay=0.01,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    fp16=True,                         \n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"macro_f1\",\n",
    "    greater_is_better=True,\n",
    "    report_to=\"none\",\n",
    "    optim=\"adamw_torch_fused\",  \n",
    "    dataloader_num_workers=8, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c21157c",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ceaef13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.8.0+cu126\n",
      "CUDA available: True\n",
      "CUDA device count: 1\n",
      "Current device index: 0\n",
      "Device name: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "CUDA version (from toolkit): 12.6\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA device count:\", torch.cuda.device_count())\n",
    "    print(\"Current device index:\", torch.cuda.current_device())\n",
    "    print(\"Device name:\", torch.cuda.get_device_name(0))\n",
    "    print(\"CUDA version (from toolkit):\", torch.version.cuda)\n",
    "else:\n",
    "    print(\"No CUDA detected by PyTorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "370ccc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc13a83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\Мариан\\AppData\\Local\\Temp\\ipykernel_2216\\2031339757.py:30: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33001' max='50757' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33001/50757 13:58:24 < 7:31:07, 0.66 it/s, Epoch 1.95/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.162100</td>\n",
       "      <td>2.068564</td>\n",
       "      <td>0.457311</td>\n",
       "      <td>0.264657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.733200</td>\n",
       "      <td>1.691451</td>\n",
       "      <td>0.534560</td>\n",
       "      <td>0.428320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.588500</td>\n",
       "      <td>1.523974</td>\n",
       "      <td>0.564881</td>\n",
       "      <td>0.470517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.420200</td>\n",
       "      <td>1.406068</td>\n",
       "      <td>0.595369</td>\n",
       "      <td>0.531457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.363900</td>\n",
       "      <td>1.339099</td>\n",
       "      <td>0.605060</td>\n",
       "      <td>0.556096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.273200</td>\n",
       "      <td>1.294651</td>\n",
       "      <td>0.617012</td>\n",
       "      <td>0.567973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>1.249300</td>\n",
       "      <td>1.242742</td>\n",
       "      <td>0.630428</td>\n",
       "      <td>0.584660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>1.231600</td>\n",
       "      <td>1.203903</td>\n",
       "      <td>0.636545</td>\n",
       "      <td>0.603474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>1.219500</td>\n",
       "      <td>1.196508</td>\n",
       "      <td>0.639238</td>\n",
       "      <td>0.601018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.192600</td>\n",
       "      <td>1.165419</td>\n",
       "      <td>0.644690</td>\n",
       "      <td>0.610899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>1.154600</td>\n",
       "      <td>1.136577</td>\n",
       "      <td>0.654432</td>\n",
       "      <td>0.618006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>1.152500</td>\n",
       "      <td>1.112144</td>\n",
       "      <td>0.658870</td>\n",
       "      <td>0.624602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>1.138300</td>\n",
       "      <td>1.087600</td>\n",
       "      <td>0.666617</td>\n",
       "      <td>0.631524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>1.129800</td>\n",
       "      <td>1.082562</td>\n",
       "      <td>0.663076</td>\n",
       "      <td>0.632832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>1.098600</td>\n",
       "      <td>1.067907</td>\n",
       "      <td>0.670623</td>\n",
       "      <td>0.638075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>1.092000</td>\n",
       "      <td>1.056547</td>\n",
       "      <td>0.673499</td>\n",
       "      <td>0.638838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>1.056600</td>\n",
       "      <td>1.042795</td>\n",
       "      <td>0.676990</td>\n",
       "      <td>0.642218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.974800</td>\n",
       "      <td>1.041925</td>\n",
       "      <td>0.676209</td>\n",
       "      <td>0.640338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>1.020400</td>\n",
       "      <td>1.027805</td>\n",
       "      <td>0.678769</td>\n",
       "      <td>0.649429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>1.023730</td>\n",
       "      <td>0.681644</td>\n",
       "      <td>0.649947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>1.013500</td>\n",
       "      <td>1.013711</td>\n",
       "      <td>0.682725</td>\n",
       "      <td>0.651442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.976900</td>\n",
       "      <td>1.006774</td>\n",
       "      <td>0.686498</td>\n",
       "      <td>0.653787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.958400</td>\n",
       "      <td>1.000988</td>\n",
       "      <td>0.687413</td>\n",
       "      <td>0.657400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.950900</td>\n",
       "      <td>1.001528</td>\n",
       "      <td>0.689258</td>\n",
       "      <td>0.658413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.973400</td>\n",
       "      <td>0.988960</td>\n",
       "      <td>0.690255</td>\n",
       "      <td>0.660226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.986700</td>\n",
       "      <td>0.982374</td>\n",
       "      <td>0.692682</td>\n",
       "      <td>0.661013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.954800</td>\n",
       "      <td>0.980856</td>\n",
       "      <td>0.693514</td>\n",
       "      <td>0.660739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.936200</td>\n",
       "      <td>0.974283</td>\n",
       "      <td>0.695043</td>\n",
       "      <td>0.666964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.927700</td>\n",
       "      <td>0.968442</td>\n",
       "      <td>0.695741</td>\n",
       "      <td>0.664840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.948100</td>\n",
       "      <td>0.967105</td>\n",
       "      <td>0.695841</td>\n",
       "      <td>0.667534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>0.922600</td>\n",
       "      <td>0.961031</td>\n",
       "      <td>0.697021</td>\n",
       "      <td>0.667236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.947400</td>\n",
       "      <td>0.954859</td>\n",
       "      <td>0.699797</td>\n",
       "      <td>0.669996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# datasets expects 'labels'\n",
    "# train_ds = train_ds.rename_column(\"label\", \"labels\")\n",
    "# val_ds   = val_ds.rename_column(\"label\", \"labels\")\n",
    "\n",
    "\n",
    "\n",
    "num_labels = 25\n",
    "\n",
    "config_train = AutoConfig.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, config=config_train)\n",
    "\n",
    "metric_acc = evaluate.load(\"accuracy\")\n",
    "metric_f1  = evaluate.load(\"f1\")\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, y_true = eval_pred\n",
    "    y_pred = np.argmax(logits, axis=1)\n",
    "    return {\n",
    "        \"accuracy\": metric_acc.compute(predictions=y_pred, references=y_true)[\"accuracy\"],\n",
    "        \"macro_f1\": metric_f1.compute(predictions=y_pred, references=y_true, average=\"macro\")[\"f1\"]\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "#last_checkpoint = config.get('model') / 'checkpoint-32000\"\n",
    "#trainer.train(resume_from_checkpoint=last_checkpoint)\n",
    "\n",
    "eval_metrics = trainer.evaluate()\n",
    "print(eval_metrics) \n",
    "\n",
    "trainer.save_model(\"bert_jobcls/best_model\")\n",
    "tokenizer.save_pretrained(\"bert_jobcls/best_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f504e8",
   "metadata": {},
   "source": [
    "### Class Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73e6eb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import ClassifierModel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6748a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('c:/Users/Мариан/Desktop/Jupyter Notes/Projects/Trainee_iFortex/Git/job_posting/notebooks')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b2eceb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'IT', 'score': 0.86962890625, 'probas': {'Accounting': 0.0030994415283203125, 'Administrative': 0.0008625984191894531, 'Automotive': 0.00019359588623046875, 'Banking': 0.0011854171752929688, 'Construction': 0.0017900466918945312, 'Consulting': 0.0108795166015625, 'Education': 0.0007853507995605469, 'Engineering': 0.09716796875, 'Finance': 0.002796173095703125, 'Government': 0.00012373924255371094, 'Healthcare': 9.053945541381836e-05, 'Hospitality': 1.9252300262451172e-05, 'IT': 0.86962890625, 'Insurance': 0.001094818115234375, 'Legal': 0.000850677490234375, 'Management': 0.0002815723419189453, 'Manufacturing': 0.0005865097045898438, 'Marketing': 0.0009908676147460938, 'Operations': 0.0027217864990234375, 'Procurement': 0.00010138750076293945, 'Retail': 6.091594696044922e-05, 'Sales': 0.00040650367736816406, 'Science': 0.0016508102416992188, 'Telecommunications': 0.0024089813232421875, 'Transportation': 0.0001932382583618164}}\n"
     ]
    }
   ],
   "source": [
    "finetuned_dir = \"../models/checkpoint-33000\"\n",
    "\n",
    "clf = ClassifierModel(finetuned_dir, finetuned=True, max_length=256)\n",
    "\n",
    "text = \"Senior Python developer needed in Amsterdam, experience with NLP required.\"\n",
    "pred = clf.predict(text, return_probas=True)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1736bd02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "job-posting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

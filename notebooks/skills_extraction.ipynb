{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26e2daad",
   "metadata": {},
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3ad853",
   "metadata": {},
   "source": [
    "### Load Modules and configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71007779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current dir for import: C:\\Users\\Мариан\\Desktop\\Jupyter Notes\\Projects\\Trainee_iFortex\\Git\\job_posting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Мариан\\Desktop\\Jupyter Notes\\Projects\\Trainee_iFortex\\Git\\job_posting\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config initialized\n"
     ]
    }
   ],
   "source": [
    "# System/env config\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "parent_dir = Path.cwd().resolve().parent\n",
    "sys.path.append(str(parent_dir))\n",
    "print('Current dir for import:', parent_dir)\n",
    "\n",
    "from src.config import Config\n",
    "config = Config()\n",
    "print('Config initialized')\n",
    "\n",
    "\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Modules for data \n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Any\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "from datasets import load_from_disk, load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoConfig, AutoModelForSequenceClassification,\n",
    "    TrainingArguments, Trainer, EarlyStoppingCallback, AutoModelForTokenClassification, DataCollatorForTokenClassification\n",
    ")\n",
    "\n",
    "import evaluate\n",
    "import torch\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import CRF\n",
    "from seqeval.metrics import f1_score as f1_span, precision_score as p_span, recall_score as r_span, classification_report\n",
    "from seqeval.scheme import IOB2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8964b5d7",
   "metadata": {},
   "source": [
    "### Dataset load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6cdc34c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ds = load_dataset(\"jjzha/skillspan\", cache_dir=config['raw_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0af079ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['idx', 'tokens', 'tags_skill', 'tags_knowledge', 'source'],\n",
       "        num_rows: 4800\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['idx', 'tokens', 'tags_skill', 'tags_knowledge', 'source'],\n",
       "        num_rows: 3174\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['idx', 'tokens', 'tags_skill', 'tags_knowledge', 'source'],\n",
       "        num_rows: 3569\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127327c5",
   "metadata": {},
   "source": [
    "### Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfc3635",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train        = ds['train'].select_columns(['tokens', 'tags_skill']).to_pandas()\n",
    "df_validation   = ds['validation'].select_columns(['tokens', 'tags_skill']).to_pandas()\n",
    "df_test         = ds['test'].select_columns(['tokens', 'tags_skill']).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dae98ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>tags_skill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Senior, QA, Engineer, (, m/f/d, ), &lt;ORGANIZAT...</td>\n",
       "      <td>[O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[&lt;ADDRESS&gt;, &lt;ADDRESS&gt;, &lt;ADDRESS&gt;, &lt;ADDRESS&gt;, &lt;...</td>\n",
       "      <td>[O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Date, posted:, 2021-07-14]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Likes:, 0, Dislikes:, 0, Love:, 0]</td>\n",
       "      <td>[O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Job, description:]</td>\n",
       "      <td>[O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4795</th>\n",
       "      <td>[Furthermore, we, expect, you, to, be, able, t...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, B, I, I, I, I, I, I, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4796</th>\n",
       "      <td>[You, are, structured, and, proactive, and, yo...</td>\n",
       "      <td>[O, O, B, O, B, O, O, O, O, B, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4797</th>\n",
       "      <td>[You, are, a, holistic, and, fact, based, prag...</td>\n",
       "      <td>[O, O, O, B, O, B, I, B, B, I, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4798</th>\n",
       "      <td>[Last, but, not, least, you, both, have, the, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, B, I, I, I, I, I, I, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4799</th>\n",
       "      <td>[Fluency, in, written, and, spoken, English, i...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tokens  \\\n",
       "0     [Senior, QA, Engineer, (, m/f/d, ), <ORGANIZAT...   \n",
       "1     [<ADDRESS>, <ADDRESS>, <ADDRESS>, <ADDRESS>, <...   \n",
       "2                           [Date, posted:, 2021-07-14]   \n",
       "3                   [Likes:, 0, Dislikes:, 0, Love:, 0]   \n",
       "4                                   [Job, description:]   \n",
       "...                                                 ...   \n",
       "4795  [Furthermore, we, expect, you, to, be, able, t...   \n",
       "4796  [You, are, structured, and, proactive, and, yo...   \n",
       "4797  [You, are, a, holistic, and, fact, based, prag...   \n",
       "4798  [Last, but, not, least, you, both, have, the, ...   \n",
       "4799  [Fluency, in, written, and, spoken, English, i...   \n",
       "\n",
       "                                             tags_skill  \n",
       "0                                 [O, O, O, O, O, O, O]  \n",
       "1                                       [O, O, O, O, O]  \n",
       "2                                             [O, O, O]  \n",
       "3                                    [O, O, O, O, O, O]  \n",
       "4                                                [O, O]  \n",
       "...                                                 ...  \n",
       "4795  [O, O, O, O, O, O, O, O, B, I, I, I, I, I, I, ...  \n",
       "4796  [O, O, B, O, B, O, O, O, O, B, O, O, O, O, O, ...  \n",
       "4797  [O, O, O, B, O, B, I, B, B, I, O, O, O, O, O, ...  \n",
       "4798  [O, O, O, O, O, O, O, O, B, I, I, I, I, I, I, ...  \n",
       "4799            [O, O, O, O, O, O, O, O, O, O, O, O, O]  \n",
       "\n",
       "[4800 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55894d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4800 entries, 0 to 4799\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   tokens      4800 non-null   object\n",
      " 1   tags_skill  4800 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 75.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a4e95c",
   "metadata": {},
   "source": [
    "Protoryping output CoNLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "311cc8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tokens, tags in zip(df_train[\"tokens\"], df_train[\"tags_skill\"]):\n",
    "#     for t, y in zip(tokens, tags):\n",
    "#         print(f\"{t}\\t{y}\")\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de065567",
   "metadata": {},
   "source": [
    "### Convert to Conll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef2ad690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of skipped rows: 0\n",
      "Number of skipped rows: 0\n",
      "Invalid BIO sequence: ['O', 'O', 'O', 'O', 'O', 'O', 'I-SKILL', 'I-SKILL', 'I-SKILL']\n",
      "\t\t\tLine: ['Experience', 'with', 'agile', 'approaches', 'to', 'software', 'testing', 'and', 'development']\n",
      "This line will be skipped\n",
      "Number of skipped rows: 1\n",
      "Done. CoNLL files saved to: C:\\Users\\Мариан\\Desktop\\Jupyter Notes\\Projects\\Trainee_iFortex\\Git\\job_posting\\data\\03_validated\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Prepare CoNLL files using only the 'tags_skill' column.\n",
    "# All comments are in English.\n",
    "def normalize_bio_tags(tags, label=\"SKILL\"):\n",
    "    \"\"\"Convert bare BIO like ['O','B','I',...] into typed BIO like ['O','B-SKILL','I-SKILL',...].\"\"\"\n",
    "    out = []\n",
    "    for t in tags:\n",
    "        if t == \"O\":\n",
    "            out.append(\"O\")\n",
    "        elif t == \"B\":\n",
    "            out.append(f\"B-{label}\")\n",
    "        elif t == \"I\":\n",
    "            out.append(f\"I-{label}\")\n",
    "        else:\n",
    "            # already typed or unexpected; keep as is\n",
    "            out.append(t)\n",
    "    return out\n",
    "\n",
    "def validate_bio_sequence(tags):\n",
    "    \"\"\"\n",
    "    Quick BIO validator: 'I-X' must follow 'B-X' or 'I-X' of the same type.\n",
    "    Returns True if valid.\n",
    "    \"\"\"\n",
    "    prev_type = None\n",
    "    prev_tag = \"O\"\n",
    "    for t in tags:\n",
    "        if t == \"O\":\n",
    "            prev_tag, prev_type = \"O\", None\n",
    "            continue\n",
    "        m = re.match(r\"([BI])-(.+)\", t)\n",
    "        if not m:\n",
    "            return False\n",
    "        bi, lab = m.groups()\n",
    "        if bi == \"B\":\n",
    "            prev_tag, prev_type = \"B\", lab\n",
    "        else:  # I\n",
    "            if prev_tag == \"O\" or prev_type != lab:\n",
    "                return False\n",
    "            prev_tag = \"I\"\n",
    "    return True\n",
    "\n",
    "def write_conll_from_df(df: pd.DataFrame, tokens_col=\"tokens\", tags_col=\"tags_skill\", out_path: Path = Path(\"train.conll\")):\n",
    "    \"\"\"\n",
    "    Write a classic CoNLL file with two columns: token<TAB>label.\n",
    "    Assumes each row has a list of tokens and a same-length list of BIO tags.\n",
    "    \"\"\"\n",
    "    skipped = 0\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with out_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        for _, row in df.iterrows():\n",
    "            tokens = list(row[tokens_col])\n",
    "            tags   = list(row[tags_col])\n",
    "            assert len(tokens) == len(tags), \"Tokens and tags length mismatch\"\n",
    "            if not validate_bio_sequence(tags):\n",
    "                print(f\"Invalid BIO sequence: {tags}\\n\\t\\t\\tLine: {tokens}\")\n",
    "                print('This line will be skipped')\n",
    "                skipped += 1\n",
    "                continue\n",
    "            for t, y in zip(tokens, tags):\n",
    "                f.write(f\"{t}\\t{y}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "    print(f'Number of skipped rows: {skipped}')\n",
    "\n",
    "# === Usage example ===\n",
    "# Suppose you already loaded df_train, df_dev, df_test with columns: \n",
    "#   [\"idx\", \"tokens\", \"tags_skill\", \"tags_knowledge\", \"source\"]\n",
    "\n",
    "for df in (df_train, df_validation, df_test):\n",
    "    df[\"tags_skill\"] = df[\"tags_skill\"].apply(lambda lst: normalize_bio_tags(lst, label=\"SKILL\"))\n",
    "\n",
    "out_dir = config['validated_dir']\n",
    "write_conll_from_df(df_train,      out_path=out_dir / \"train.conll\"     )\n",
    "write_conll_from_df(df_validation, out_path=out_dir / \"validation.conll\")\n",
    "write_conll_from_df(df_test,       out_path=out_dir / \"test.conll\"      )\n",
    "\n",
    "print(\"Done. CoNLL files saved to:\", out_dir.resolve())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a04c457",
   "metadata": {},
   "source": [
    "### Read Conll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "245ab068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#train sents: 4800  #val: 3174  #test: 3568\n"
     ]
    }
   ],
   "source": [
    "def read_conll(path: Path) -> tuple[list[list[str]], list[list[str]]]:\n",
    "    \"\"\"\n",
    "    Read a two-column CoNLL file (token<TAB>tag>), sentences separated by blank lines.\n",
    "    Returns: tokens_per_sent, tags_per_sent as lists of lists.\n",
    "    \"\"\"\n",
    "    s_tokens, s_tags = [], []\n",
    "    tokens, tags = [], []\n",
    "    with path.open(encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.rstrip(\"\\n\")\n",
    "            if not line:\n",
    "                if tokens:\n",
    "                    s_tokens.append(tokens)\n",
    "                    s_tags.append(tags)\n",
    "                    tokens, tags = [], []\n",
    "                continue\n",
    "            parts = line.split(\"\\t\")\n",
    "            if len(parts) != 2:\n",
    "                # Skip malformed lines safely\n",
    "                continue\n",
    "            tok, lab = parts\n",
    "            tokens.append(tok)\n",
    "            tags.append(lab)\n",
    "    if tokens:\n",
    "        s_tokens.append(tokens)\n",
    "        s_tags.append(tags)\n",
    "    return s_tokens, s_tags\n",
    "\n",
    "\n",
    "\n",
    "X_tokens_train, y_train = read_conll(config['train_connl'])\n",
    "X_tokens_val,   y_val   = read_conll(config['validation_connl'])\n",
    "X_tokens_test,  y_test  = read_conll(config['test_connl'])\n",
    "\n",
    "\n",
    "print(f\"#train sents: {len(X_tokens_train)}  #val: {len(X_tokens_val)}  #test: {len(X_tokens_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae47dd8",
   "metadata": {},
   "source": [
    "## CRF Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645f0c97",
   "metadata": {},
   "source": [
    "### Building features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57f0be0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2184, 5944)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_skill_gazetteers(tokens_per_sent: list[list[str]], tags_per_sent: list[list[str]]) -> dict[str, set[str]]:\n",
    "    \"\"\"\n",
    "    Build simple gazetteers from training data:\n",
    "      - skill_unigrams: lowercased tokens appearing inside any SKILL span\n",
    "      - skill_bigrams:  lowercased bigrams inside SKILL spans\n",
    "    \"\"\"\n",
    "    skill_unigrams = set()\n",
    "    skill_bigrams  = set()\n",
    "    for toks, labs in zip(tokens_per_sent, tags_per_sent):\n",
    "        # collect indices of tokens inside SKILL spans (B-SKILL / I-SKILL)\n",
    "        inside = [i for i, t in enumerate(labs) if t.startswith(\"B-\") or t.startswith(\"I-\")]\n",
    "        for i in inside:\n",
    "            skill_unigrams.add(toks[i].lower())\n",
    "        # bigrams (consecutive tokens both inside a span)\n",
    "        for i in range(len(toks) - 1):\n",
    "            if (labs[i].startswith((\"B-\",\"I-\"))) and (labs[i+1].startswith((\"B-\",\"I-\"))):\n",
    "                skill_bigrams.add((toks[i].lower(), toks[i+1].lower()))\n",
    "    return {\"skill_unigrams\": skill_unigrams, \"skill_bigrams\": skill_bigrams}\n",
    "\n",
    "gazetteers = build_skill_gazetteers(X_tokens_train, y_train)\n",
    "len(gazetteers[\"skill_unigrams\"]), len(gazetteers[\"skill_bigrams\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a13f2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 400)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def char_ngrams(token: str, n: int) -> list[str]:\n",
    "    token = token\n",
    "    return [token[i:i+n] for i in range(len(token) - n + 1)] if len(token) >= n else []\n",
    "\n",
    "def top_char_ngrams(tokens_per_sent: list[list[str]], top_k: int = 400) -> dict[str, set[str]]:\n",
    "    \"\"\"\n",
    "    Compute most frequent char 2-grams and 3-grams from TRAIN tokens only and keep top_k for each size.\n",
    "    This caps feature explosion while still giving CRF helpful subword signals.\n",
    "    \"\"\"\n",
    "    c2 = Counter()\n",
    "    c3 = Counter()\n",
    "    for sent in tokens_per_sent:\n",
    "        for tok in sent:\n",
    "            c2.update(char_ngrams(tok, 2))\n",
    "            c3.update(char_ngrams(tok, 3))\n",
    "    top2 = set([ng for ng, _ in c2.most_common(top_k)])\n",
    "    top3 = set([ng for ng, _ in c3.most_common(top_k)])\n",
    "    return {\"char2\": top2, \"char3\": top3}\n",
    "\n",
    "char_ngram_vocab = top_char_ngrams(X_tokens_train, top_k=400)\n",
    "len(char_ngram_vocab[\"char2\"]), len(char_ngram_vocab[\"char3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "347e8c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREF_SIZES = (2, 3, 4)\n",
    "SUFF_SIZES = (2, 3, 4)\n",
    "\n",
    "def word_shape(token: str) -> str:\n",
    "    \"\"\"\n",
    "    Map token to a coarse 'shape' (e.g., 'Xx', 'xxx', 'd-dd', 'xxx-xx', 'Xx.' etc.).\n",
    "    Helps generalize across casing/digits/punct.\n",
    "    \"\"\"\n",
    "    shape = []\n",
    "    for ch in token:\n",
    "        if ch.isupper():\n",
    "            shape.append('X')\n",
    "        elif ch.islower():\n",
    "            shape.append('x')\n",
    "        elif ch.isdigit():\n",
    "            shape.append('d')\n",
    "        elif ch in \"-_/\\\\.\":\n",
    "            shape.append(ch)\n",
    "        else:\n",
    "            shape.append('p')  # other punct\n",
    "    # collapse runs like XXX -> X, xxx -> x to reduce sparsity\n",
    "    collapsed = []\n",
    "    for ch in shape:\n",
    "        if not collapsed or collapsed[-1] != ch:\n",
    "            collapsed.append(ch)\n",
    "    return ''.join(collapsed)\n",
    "\n",
    "def token_features(sent: list[str], i: int,\n",
    "                   gaz: dict[str, set[str]],\n",
    "                   char_vocab: dict[str, set[str]]) -> dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Build a feature dict for token sent[i].\n",
    "    Includes:\n",
    "      - bias, word lowercase, shape, isupper/istitle/isdigit/has_digit/has_hyphen\n",
    "      - prefixes/suffixes, limited char 2/3-grams (only if in top lists)\n",
    "      - simple gazetteers (unigram + adjacent bigrams), plus +/-1 and +/-2 window features\n",
    "    \"\"\"\n",
    "    token = sent[i]\n",
    "    lower = token.lower()\n",
    "    feats = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower': lower,\n",
    "        'word.shape': word_shape(token),\n",
    "        'word.isupper': token.isupper(),\n",
    "        'word.istitle': token.istitle(),\n",
    "        'word.isdigit': token.isdigit(),\n",
    "        'word.has_digit': any(ch.isdigit() for ch in token),\n",
    "        'word.has_hyphen': '-' in token,\n",
    "        'word.has_dot': '.' in token,\n",
    "        'word.has_slash': '/' in token or '\\\\' in token,\n",
    "        'gaz.in_skill_unigram': (lower in gaz['skill_unigrams']),\n",
    "    }\n",
    "    # prefixes / suffixes\n",
    "    for n in PREF_SIZES:\n",
    "        feats[f'pref{n}'] = lower[:n] if len(lower) >= n else lower\n",
    "    for n in SUFF_SIZES:\n",
    "        feats[f'suff{n}'] = lower[-n:] if len(lower) >= n else lower\n",
    "\n",
    "    # limited char 2/3-grams (only those that are in top vocab to control dimensionality)\n",
    "    for ng in char_ngrams(token, 2):\n",
    "        if ng in char_vocab['char2']:\n",
    "            feats[f'char2={ng}'] = True\n",
    "    for ng in char_ngrams(token, 3):\n",
    "        if ng in char_vocab['char3']:\n",
    "            feats[f'char3={ng}'] = True\n",
    "\n",
    "    # context features (+/- 1, +/- 2)\n",
    "    def add_ctx(j: int, tag: str):\n",
    "        if 0 <= j < len(sent):\n",
    "            w = sent[j]\n",
    "            lw = w.lower()\n",
    "            feats[f'{tag}.lower'] = lw\n",
    "            feats[f'{tag}.shape'] = word_shape(w)\n",
    "            feats[f'{tag}.istitle'] = w.istitle()\n",
    "            feats[f'{tag}.isupper'] = w.isupper()\n",
    "\n",
    "    add_ctx(i-1, '-1')\n",
    "    add_ctx(i-2, '-2')\n",
    "    add_ctx(i+1, '+1')\n",
    "    add_ctx(i+2, '+2')\n",
    "\n",
    "    # gazetteer bigrams with neighbors (prev+cur, cur+next)\n",
    "    if i-1 >= 0:\n",
    "        feats['gaz.prev_cur_in_skill_bigram'] = (sent[i-1].lower(), lower) in gaz['skill_bigrams']\n",
    "    if i+1 < len(sent):\n",
    "        feats['gaz.cur_next_in_skill_bigram'] = (lower, sent[i+1].lower()) in gaz['skill_bigrams']\n",
    "\n",
    "    return feats\n",
    "\n",
    "def sent2features(sent: list[str],\n",
    "                  gaz: dict[str, set[str]],\n",
    "                  char_vocab: dict[str, set[str]]) -> list[dict[str, Any]]:\n",
    "    return [token_features(sent, i, gaz, char_vocab) for i in range(len(sent))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bd8b048f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800 4800 3174 3174\n",
      "7 7 {'bias': 1.0, 'word.lower': 'senior', 'word.shape': 'Xx', 'word.isupper': False, 'word.istitle': True, 'word.isdigit': False, 'word.has_digit': False, 'word.has_hyphen': False, 'word.has_dot': False, 'word.has_slash': False, 'gaz.in_skill_unigram': True, 'pref2': 'se', 'pref3': 'sen', 'pref4': 'seni', 'suff2': 'or', 'suff3': 'ior', 'suff4': 'nior', 'char2=Se': True, 'char2=en': True, 'char2=ni': True, 'char2=io': True, 'char2=or': True, '+1.lower': 'qa', '+1.shape': 'X', '+1.istitle': False, '+1.isupper': True, '+2.lower': 'engineer', '+2.shape': 'Xx', '+2.istitle': True, '+2.isupper': False, 'gaz.cur_next_in_skill_bigram': False}\n"
     ]
    }
   ],
   "source": [
    "def to_crf_Xy(tokens_per_sent: list[list[str]],\n",
    "              tags_per_sent: list[list[str]],\n",
    "              gaz: dict[str, set[str]],\n",
    "              char_vocab: dict[str, set[str]]):\n",
    "    X = [sent2features(s, gaz, char_vocab) for s in tokens_per_sent]\n",
    "    y = [list(tags) for tags in tags_per_sent]\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train_ = to_crf_Xy(X_tokens_train, y_train, gazetteers, char_ngram_vocab)\n",
    "X_val_,  y_val_   = to_crf_Xy(X_tokens_val,   y_val,   gazetteers, char_ngram_vocab)\n",
    "X_test_, y_test_  = to_crf_Xy(X_tokens_test,  y_test,  gazetteers, char_ngram_vocab)\n",
    "\n",
    "# Quick sanity check\n",
    "print(len(X_train), len(y_train_), len(X_val_), len(y_val_))\n",
    "print(len(X_train[0]), len(y_train_[0]), X_train[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97fdbd3",
   "metadata": {},
   "source": [
    "### Train CRF pand evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ed900a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRF trained.\n"
     ]
    }
   ],
   "source": [
    "crf = CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,               # L1\n",
    "    c2=0.1,               # L2\n",
    "    max_iterations=200,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "\n",
    "crf.fit(X_train, y_train_)\n",
    "print(\"CRF trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c04f1cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Val [oracle sanity] (span-level) ===\n",
      "Precision: 1.0000  Recall: 1.0000  F1: 1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       SKILL     1.0000    1.0000    1.0000      1070\n",
      "\n",
      "   micro avg     1.0000    1.0000    1.0000      1070\n",
      "   macro avg     1.0000    1.0000    1.0000      1070\n",
      "weighted avg     1.0000    1.0000    1.0000      1070\n",
      "\n",
      "=== Val (span-level) ===\n",
      "Precision: 0.3375  Recall: 0.1000  F1: 0.1543\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       SKILL     0.3375    0.1000    0.1543      1070\n",
      "\n",
      "   micro avg     0.3375    0.1000    0.1543      1070\n",
      "   macro avg     0.3375    0.1000    0.1543      1070\n",
      "weighted avg     0.3375    0.1000    0.1543      1070\n",
      "\n",
      "=== Test (span-level) ===\n",
      "Precision: 0.3607  Recall: 0.1009  F1: 0.1577\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       SKILL     0.3607    0.1009    0.1577      1090\n",
      "\n",
      "   micro avg     0.3607    0.1009    0.1577      1090\n",
      "   macro avg     0.3607    0.1009    0.1577      1090\n",
      "weighted avg     0.3607    0.1009    0.1577      1090\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def eval_seqeval(y_true, y_pred, title: str = \"Eval\"):\n",
    "    print(f\"=== {title} (span-level) ===\")\n",
    "    p = p_span(y_true, y_pred, scheme=IOB2)\n",
    "    r = r_span(y_true, y_pred, scheme=IOB2)\n",
    "    f = f1_span(y_true, y_pred, scheme=IOB2)\n",
    "    print(f\"Precision: {p:.4f}  Recall: {r:.4f}  F1: {f:.4f}\")\n",
    "    print(classification_report(y_true, y_pred, scheme=IOB2, digits=4))\n",
    "\n",
    "y_val_pred  = crf.predict(X_val_)\n",
    "y_test_pred = crf.predict(X_test_)\n",
    "\n",
    "eval_seqeval(y_val_,  y_val_,  title=\"Val [oracle sanity]\")     # sanity: should be 1.0\n",
    "eval_seqeval(y_val_,  y_val_pred,  title=\"Val\")\n",
    "eval_seqeval(y_test_, y_test_pred, title=\"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c858bb1c",
   "metadata": {},
   "source": [
    "## BERT-MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa9d77e",
   "metadata": {},
   "source": [
    "### Read and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01aad3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = config['train_connl']\n",
    "val_path   = config['validation_connl']\n",
    "test_path  = config['test_connl']\n",
    "\n",
    "X_train_tok, y_train_bio = read_conll(train_path)\n",
    "X_val_tok,   y_val_bio   = read_conll(val_path)\n",
    "X_test_tok,  y_test_bio  = read_conll(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97cec68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800 3174 3568\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_tok), len(X_val_tok), len(X_test_tok))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67487e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = sorted({lab for seq in (y_train_bio + y_val_bio + y_test_bio) for lab in seq})\n",
    "assert all(lab == \"O\" or lab.startswith((\"B-\",\"I-\")) for lab in label_list), f\"Non-BIO labels: {label_list}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c059fec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['O', 'B-SKILL', 'I-SKILL'],\n",
       " {'O': 0, 'B-SKILL': 1, 'I-SKILL': 2},\n",
       " {0: 'O', 1: 'B-SKILL', 2: 'I-SKILL'})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list = [\"O\"] + [l for l in label_list if l != \"O\"]\n",
    "label2id = {l:i for i,l in enumerate(label_list)}\n",
    "id2label = {i:l for l,i in label2id.items()}\n",
    "label_list, label2id, id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "01cc52d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_hf(tokens: list[list[str]], labels: list[list[str]]) -> Dataset:\n",
    "    ids = [[label2id[t] for t in seq] for seq in labels]\n",
    "    return Dataset.from_dict({\"tokens\": tokens, \"labels\": ids})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "93d0f5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'labels'],\n",
       "        num_rows: 4800\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'labels'],\n",
       "        num_rows: 3174\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'labels'],\n",
       "        num_rows: 3568\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = DatasetDict({\n",
    "    \"train\": to_hf(X_train_tok, y_train_bio),\n",
    "    \"validation\": to_hf(X_val_tok, y_val_bio),\n",
    "    \"test\": to_hf(X_test_tok, y_test_bio),\n",
    "})\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2513f679",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4800/4800 [00:00<00:00, 13290.57 examples/s]\n",
      "Map: 100%|██████████| 3174/3174 [00:00<00:00, 18293.64 examples/s]\n",
      "Map: 100%|██████████| 3568/3568 [00:00<00:00, 19127.08 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 4800\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 3174\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 3568\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"bert-base-cased\"  # casing helps for NER\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "\n",
    "def tokenize_and_align(batch: dict[str, Any], label_all_tokens: bool = False) -> dict[str, Any]:\n",
    "    enc = tokenizer(\n",
    "        batch[\"tokens\"],\n",
    "        is_split_into_words=True,\n",
    "        truncation=True,\n",
    "        padding=False,\n",
    "        max_length=256,\n",
    "    )\n",
    "    all_labels = []\n",
    "    for i in range(len(batch[\"tokens\"])):\n",
    "        word_ids = enc.word_ids(batch_index=i)\n",
    "        labels_i = batch[\"labels\"][i]\n",
    "        aligned = []\n",
    "        prev_wid = None\n",
    "        for wid in word_ids:\n",
    "            if wid is None:\n",
    "                aligned.append(-100)\n",
    "            elif wid != prev_wid:\n",
    "                aligned.append(labels_i[wid])\n",
    "            else:\n",
    "                aligned.append(labels_i[wid] if label_all_tokens else -100)\n",
    "            prev_wid = wid\n",
    "        all_labels.append(aligned)\n",
    "    enc[\"labels\"] = all_labels\n",
    "    return enc\n",
    "\n",
    "encoded = DatasetDict({\n",
    "    \"train\": ds[\"train\"].map(tokenize_and_align, batched=True, remove_columns=ds[\"train\"].column_names),\n",
    "    \"validation\": ds[\"validation\"].map(tokenize_and_align, batched=True, remove_columns=ds[\"validation\"].column_names),\n",
    "    \"test\": ds[\"test\"].map(tokenize_and_align, batched=True, remove_columns=ds[\"test\"].column_names),\n",
    "})\n",
    "encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f012c623",
   "metadata": {},
   "source": [
    "### Arguments and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386c7df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(label_list),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ").to(device)\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "def align_for_metrics(predictions: np.ndarray, labels: np.ndarray) -> tuple[list[list[str]], list[list[str]]]:\n",
    "    preds = np.argmax(predictions, axis=2)\n",
    "    y_true, y_pred = [], []\n",
    "    for p_seq, l_seq in zip(preds, labels):\n",
    "        true_tags, pred_tags = [], []\n",
    "        for p, l in zip(p_seq, l_seq):\n",
    "            if l == -100:\n",
    "                continue\n",
    "            true_tags.append(id2label[int(l)])\n",
    "            pred_tags.append(id2label[int(p)])\n",
    "        y_true.append(true_tags)\n",
    "        y_pred.append(pred_tags)\n",
    "    return y_true, y_pred\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    y_true, y_pred = align_for_metrics(logits, labels)\n",
    "    return {\n",
    "        \"precision\": p_span(y_true, y_pred, scheme=IOB2),\n",
    "        \"recall\":    r_span(y_true, y_pred, scheme=IOB2),\n",
    "        \"f1\":        f1_span(y_true, y_pred, scheme=IOB2),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a51537e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Мариан\\AppData\\Local\\Temp\\ipykernel_8036\\24730069.py:24: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 06:25, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.098400</td>\n",
       "      <td>0.238525</td>\n",
       "      <td>0.430918</td>\n",
       "      <td>0.416822</td>\n",
       "      <td>0.423753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>0.279275</td>\n",
       "      <td>0.464822</td>\n",
       "      <td>0.549533</td>\n",
       "      <td>0.503640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>0.315194</td>\n",
       "      <td>0.482173</td>\n",
       "      <td>0.530841</td>\n",
       "      <td>0.505338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1500, training_loss=0.09613342535495759, metrics={'train_runtime': 386.0806, 'train_samples_per_second': 62.163, 'train_steps_per_second': 3.885, 'total_flos': 1428260985022464.0, 'train_loss': 0.09613342535495759, 'epoch': 5.0})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dir = str(config['models_dir'] / \"bert-skill-ner\" )\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=out_dir,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=5,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=100,\n",
    "    report_to=\"none\",\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=encoded[\"train\"],\n",
    "    eval_dataset=encoded[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecf97a1",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "616d2c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== VALIDATION (span-level, IOB2) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       SKILL     0.4822    0.5308    0.5053      1070\n",
      "\n",
      "   micro avg     0.4822    0.5308    0.5053      1070\n",
      "   macro avg     0.4822    0.5308    0.5053      1070\n",
      "weighted avg     0.4822    0.5308    0.5053      1070\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TEST (span-level, IOB2) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       SKILL     0.4896    0.4734    0.4813      1090\n",
      "\n",
      "   micro avg     0.4896    0.4734    0.4813      1090\n",
      "   macro avg     0.4896    0.4734    0.4813      1090\n",
      "weighted avg     0.4896    0.4734    0.4813      1090\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Detailed per-entity report\n",
    "def classification_report_on(split: str):\n",
    "    preds = trainer.predict(encoded[split])\n",
    "    y_true, y_pred = align_for_metrics(preds.predictions, preds.label_ids)\n",
    "    print(f\"\\n=== {split.upper()} (span-level, IOB2) ===\")\n",
    "    print(classification_report(y_true, y_pred, scheme=IOB2, digits=4))\n",
    "\n",
    "classification_report_on(\"validation\")\n",
    "classification_report_on(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2f1ab188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- VALIDATION example #20 ---\n",
      "TOKENS: We are in growth mode and looking for high calibre deeply experienced hands-on DevOps engineers who seek to be recognized as platform technology leaders growing our practice .\n",
      "TRUE:   O O O O O O O O B-SKILL I-SKILL O B-SKILL B-SKILL O O O O O O O O O O O O O O O\n",
      "PRED:   O O O O O O O O O O O O B-SKILL O O O O O O O O O O O O O O O\n",
      "TP: [Span(label='SKILL', start=12, end=12)]\n",
      "FP: []\n",
      "FN: [Span(label='SKILL', start=8, end=9), Span(label='SKILL', start=11, end=11)]\n",
      "\n",
      "--- VALIDATION example #21 ---\n",
      "TOKENS: You will work as part of our Agile hybrid DevOps teams to help develop/configure new tools roll out environments and automate processes using a variety of tools and techniques .\n",
      "TRUE:   O O O O O O O O O O O O O B-SKILL I-SKILL I-SKILL B-SKILL I-SKILL I-SKILL O B-SKILL I-SKILL O O O O O O O O\n",
      "PRED:   O O O O O O O O O O O O O B-SKILL I-SKILL I-SKILL I-SKILL I-SKILL I-SKILL O B-SKILL I-SKILL O I-SKILL I-SKILL I-SKILL I-SKILL I-SKILL I-SKILL O\n",
      "TP: [Span(label='SKILL', start=20, end=21)]\n",
      "FP: [Span(label='SKILL', start=13, end=18)]\n",
      "FN: [Span(label='SKILL', start=13, end=15), Span(label='SKILL', start=16, end=18)]\n",
      "\n",
      "--- VALIDATION example #22 ---\n",
      "TOKENS: This role will give you the opportunity to leverage your current technical skills whilst building your knowledge on the job .\n",
      "TRUE:   O O O O O O O O O O O O O O O O O O O O O\n",
      "PRED:   O O O O O O O O B-SKILL I-SKILL O I-SKILL I-SKILL O B-SKILL I-SKILL I-SKILL I-SKILL I-SKILL I-SKILL O\n",
      "TP: []\n",
      "FP: [Span(label='SKILL', start=8, end=9), Span(label='SKILL', start=14, end=19)]\n",
      "FN: []\n",
      "\n",
      "--- VALIDATION example #27 ---\n",
      "TOKENS: Uses testing as a baseline practice: TDD BDD integration E2E\n",
      "TRUE:   B-SKILL I-SKILL I-SKILL I-SKILL I-SKILL I-SKILL O O O O\n",
      "PRED:   O O O O O O O O O O\n",
      "TP: []\n",
      "FP: []\n",
      "FN: [Span(label='SKILL', start=0, end=5)]\n",
      "\n",
      "--- VALIDATION example #28 ---\n",
      "TOKENS: Understands the challenges presented by cloud adoption and migration in both enterprise and green field contexts; how to build cloud native applications scratch and how to tackle monolithic system estates through the introduction of API’s microservices and gateways\n",
      "TRUE:   O O O O O O O O O O O O O O O O O O B-SKILL I-SKILL I-SKILL I-SKILL I-SKILL O O O B-SKILL I-SKILL I-SKILL I-SKILL O O O O O O O O\n",
      "PRED:   O O O O O O O O O O O O O O O O O O B-SKILL I-SKILL I-SKILL I-SKILL O O O O B-SKILL I-SKILL I-SKILL I-SKILL O O O O O O O O\n",
      "TP: [Span(label='SKILL', start=26, end=29)]\n",
      "FP: [Span(label='SKILL', start=18, end=21)]\n",
      "FN: [Span(label='SKILL', start=18, end=22)]\n",
      "\n",
      "--- VALIDATION example #29 ---\n",
      "TOKENS: Hands on practitioners with the ability to demonstrate and communicate at all levels bringing complex technological issues into perspective for specialists and laymen alike enabling our clients to adapt to changing needs improve their time to live and deliver better solutions though better software .\n",
      "TRUE:   B-SKILL I-SKILL O O O O O O O B-SKILL I-SKILL I-SKILL I-SKILL B-SKILL I-SKILL I-SKILL I-SKILL I-SKILL I-SKILL O O O O O B-SKILL I-SKILL I-SKILL I-SKILL I-SKILL I-SKILL I-SKILL I-SKILL O O O O O O B-SKILL I-SKILL I-SKILL O O O O\n",
      "PRED:   B-SKILL I-SKILL O O O O O B-SKILL I-SKILL I-SKILL I-SKILL I-SKILL I-SKILL B-SKILL I-SKILL I-SKILL I-SKILL I-SKILL I-SKILL O O O O O B-SKILL O O O O O O O B-SKILL O O O O O B-SKILL I-SKILL I-SKILL I-SKILL I-SKILL I-SKILL O\n",
      "TP: [Span(label='SKILL', start=0, end=1), Span(label='SKILL', start=13, end=18)]\n",
      "FP: [Span(label='SKILL', start=7, end=12), Span(label='SKILL', start=24, end=24), Span(label='SKILL', start=32, end=32), Span(label='SKILL', start=38, end=43)]\n",
      "FN: [Span(label='SKILL', start=9, end=12), Span(label='SKILL', start=24, end=31), Span(label='SKILL', start=38, end=40)]\n",
      "\n",
      "--- VALIDATION example #39 ---\n",
      "TOKENS: Consulting experience preferably with major IT consulting or Big 4\n",
      "TRUE:   B-SKILL O O O O O O O O O\n",
      "PRED:   O O O O O O O O O O\n",
      "TP: []\n",
      "FP: []\n",
      "FN: [Span(label='SKILL', start=0, end=0)]\n",
      "\n",
      "--- VALIDATION example #41 ---\n",
      "TOKENS: Highly articulate with good communication skills across diverse groups including stakeholders engineers business analysts and teams\n",
      "TRUE:   O B-SKILL O O B-SKILL I-SKILL O O O O O O O O O O\n",
      "PRED:   O O O O B-SKILL I-SKILL O O O O O O O O O O\n",
      "TP: [Span(label='SKILL', start=4, end=5)]\n",
      "FP: []\n",
      "FN: [Span(label='SKILL', start=1, end=1)]\n"
     ]
    }
   ],
   "source": [
    "from typing import NamedTuple, Set\n",
    "\n",
    "class Span(NamedTuple):\n",
    "    label: str\n",
    "    start: int\n",
    "    end: int  # inclusive\n",
    "\n",
    "def bio_to_spans(tags: list[str]) -> list[Span]:\n",
    "    spans, start, lab = [], None, None\n",
    "    for i, t in enumerate(tags):\n",
    "        if t == \"O\":\n",
    "            if lab is not None:\n",
    "                spans.append(Span(lab, start, i-1))\n",
    "                lab, start = None, None\n",
    "            continue\n",
    "        bi, typ = t.split(\"-\", 1)\n",
    "        if bi == \"B\":\n",
    "            if lab is not None:\n",
    "                spans.append(Span(lab, start, i-1))\n",
    "            lab, start = typ, i\n",
    "        elif bi == \"I\":\n",
    "            pass\n",
    "    if lab is not None:\n",
    "        spans.append(Span(lab, start, len(tags)-1))\n",
    "    return spans\n",
    "\n",
    "def compare_spans(true_spans: list[Span], pred_spans: list[Span]) -> tuple[set[Span], set[Span], set[Span]]:\n",
    "    true_set, pred_set = set(true_spans), set(pred_spans)\n",
    "    return true_set & pred_set, pred_set - true_set, true_set - pred_set\n",
    "\n",
    "def show_errors(split=\"validation\", max_examples=8):\n",
    "    # We need original tokens for display (read them again from your CoNLL-based python lists)\n",
    "    orig_tokens = {\"validation\": X_val_tok, \"test\": X_test_tok, \"train\": X_train_tok}[split]\n",
    "    preds = trainer.predict(encoded[split])\n",
    "    y_true, y_pred = align_for_metrics(preds.predictions, preds.label_ids)\n",
    "    shown = 0\n",
    "    for i, (tseq, pseq) in enumerate(zip(y_true, y_pred)):\n",
    "        tp, fp, fn = compare_spans(bio_to_spans(tseq), bio_to_spans(pseq))\n",
    "        if not fp and not fn:\n",
    "            continue\n",
    "        print(f\"\\n--- {split.upper()} example #{i} ---\")\n",
    "        print(\"TOKENS:\", \" \".join(orig_tokens[i]))\n",
    "        print(\"TRUE:  \", \" \".join(tseq))\n",
    "        print(\"PRED:  \", \" \".join(pseq))\n",
    "        print(\"TP:\", sorted(tp))\n",
    "        print(\"FP:\", sorted(fp))\n",
    "        print(\"FN:\", sorted(fn))\n",
    "        shown += 1\n",
    "        if shown >= max_examples:\n",
    "            break\n",
    "\n",
    "show_errors(\"validation\", max_examples=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09b7a18",
   "metadata": {},
   "source": [
    "### Class check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cd0e2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.skills_model import SkillExtractor\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f0d55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4800/4800 [00:00<00:00, 14140.73 examples/s]\n",
      "Map: 100%|██████████| 3174/3174 [00:00<00:00, 17422.77 examples/s]\n",
      "Map: 100%|██████████| 3568/3568 [00:00<00:00, 20250.14 examples/s]\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\Мариан\\Desktop\\Jupyter Notes\\Projects\\Trainee_iFortex\\Git\\job_posting\\src\\skills_model.py:188: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  self.trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 18:51, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.097500</td>\n",
       "      <td>0.238221</td>\n",
       "      <td>0.454635</td>\n",
       "      <td>0.430841</td>\n",
       "      <td>0.442418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.273246</td>\n",
       "      <td>0.464006</td>\n",
       "      <td>0.554206</td>\n",
       "      <td>0.505111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>0.300179</td>\n",
       "      <td>0.489398</td>\n",
       "      <td>0.539252</td>\n",
       "      <td>0.513117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== VALIDATION (span-level, IOB2) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       SKILL     0.4894    0.5393    0.5131      1070\n",
      "\n",
      "   micro avg     0.4894    0.5393    0.5131      1070\n",
      "   macro avg     0.4894    0.5393    0.5131      1070\n",
      "weighted avg     0.4894    0.5393    0.5131      1070\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TEST (span-level, IOB2) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       SKILL     0.4874    0.4954    0.4914      1090\n",
      "\n",
      "   micro avg     0.4874    0.4954    0.4914      1090\n",
      "   macro avg     0.4874    0.4954    0.4914      1090\n",
      "weighted avg     0.4874    0.4954    0.4914      1090\n",
      "\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_path = Path(\"../data/03_validated/train.conll\")\n",
    "val_path   = Path(\"../data/03_validated/validation.conll\")\n",
    "test_path  = Path(\"../data/03_validated/test.conll\")\n",
    "se = SkillExtractor(model_name=\"bert-base-cased\", max_length=256)\n",
    "se.prepare_from_conll(train_path, val_path, test_path)\n",
    "\n",
    "out_dir = Path(\"../models/bert-skill-ner/test\")\n",
    "se.fit(output_dir=out_dir, early_stopping_patience=3)\n",
    "se.evaluate(\"validation\")\n",
    "se.evaluate(\"test\")\n",
    "\n",
    "save_dir = out_dir / \"final\"\n",
    "se.save(save_dir)\n",
    "\n",
    "se2 = SkillExtractor.load(save_dir)\n",
    "\n",
    "text = \"Senior Python Developer with FastAPI, Docker and a bit of Kubernetes; strong SQL.\"\n",
    "skills = se2.predict(text)               \n",
    "print(skills)\n",
    "\n",
    "skills_all = se2.predict(text, unique=False)\n",
    "print(skills_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "994dc893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['develop/configure new tools roll out environments', 'automate processes']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"You will work as part of our Agile hybrid DevOps teams to help develop/configure new tools roll out environments and automate processes using a variety of tools and techniques\"\n",
    "skills = se2.predict(text)               \n",
    "skills\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3a97278a",
   "metadata": {},
   "outputs": [],
   "source": [
    "manualy_trained = Path(\"../models/bert-skill-ner/checkpoint-1500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf29594",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "skills_all = se2.predict(text, unique=False)\n",
    "print(skills_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8c0ba91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(manualy_trained)\n",
    "tokenizer = AutoTokenizer.from_pretrained(manualy_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d58ac1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER: [[], [], [], [{'entity_group': 'SKILL', 'score': np.float32(0.9988899), 'word': 'develop / configure new tools roll out environments', 'start': 63, 'end': 112}, {'entity_group': 'SKILL', 'score': np.float32(0.98706126), 'word': 'auto', 'start': 117, 'end': 121}, {'entity_group': 'SKILL', 'score': np.float32(0.9881214), 'word': '##mate processes', 'start': 121, 'end': 135}, {'entity_group': 'SKILL', 'score': np.float32(0.7099903), 'word': 'a variety of tools and techniques', 'start': 142, 'end': 175}]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " [],\n",
       " [],\n",
       " [{'entity_group': 'SKILL',\n",
       "   'score': np.float32(0.9988899),\n",
       "   'word': 'develop / configure new tools roll out environments',\n",
       "   'start': 63,\n",
       "   'end': 112},\n",
       "  {'entity_group': 'SKILL',\n",
       "   'score': np.float32(0.98706126),\n",
       "   'word': 'auto',\n",
       "   'start': 117,\n",
       "   'end': 121},\n",
       "  {'entity_group': 'SKILL',\n",
       "   'score': np.float32(0.9881214),\n",
       "   'word': '##mate processes',\n",
       "   'start': 121,\n",
       "   'end': 135},\n",
       "  {'entity_group': 'SKILL',\n",
       "   'score': np.float32(0.7099903),\n",
       "   'word': 'a variety of tools and techniques',\n",
       "   'start': 142,\n",
       "   'end': 175}]]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# \n",
    "# task = \"text-classification\"\n",
    "# model_or_dir = \"save_dir\"                \n",
    "# clf = pipeline(task=task, model=model, device_map=\"auto\", tokenizer = tokenizer) \n",
    "\n",
    "# texts = [\"I loved this film!\", \"Service was terrible.\", 'Python']\n",
    "# preds_clf = clf(texts, truncation=True, top_k=1) \n",
    "# print(\"Classification:\", preds_clf)\n",
    "\n",
    "# \n",
    "ner = pipeline(task=\"token-classification\", model=model, aggregation_strategy=\"simple\", device_map=\"auto\",  tokenizer = tokenizer)\n",
    "ner_text = [\"Full Stack Software Engineer – Java/JavaScript\", ' Hello', 'Python Developer' , 'You will work as part of our Agile hybrid DevOps teams to help develop/configure new tools roll out environments and automate processes using a variety of tools and techniques'] \n",
    "preds_ner = ner(ner_text)\n",
    "print(\"NER:\", preds_ner)\n",
    "preds_ner\n",
    "\n",
    "# # \n",
    "# clf_all = pipeline(task=\"text-classification\", model=model_or_dir, device_map=\"auto\", return_all_scores=True)\n",
    "# print(\"All scores:\", clf_all(\"The product is fine, but shipping was slow.\"))\n",
    "\n",
    "# \n",
    "# quick = pipeline(\"text-classification\", model=\"distilbert-base-uncased-finetuned-sst-2-english\", device_map=\"auto\")\n",
    "# print(\"Quick:\", quick(\"What a fantastic day!\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "job-posting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f3ad853",
   "metadata": {},
   "source": [
    "### INIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71007779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current dir for import: C:\\Users\\Мариан\\Desktop\\Jupyter Notes\\Projects\\Trainee_iFortex\\Git\\job_posting\n",
      "Config initialized\n"
     ]
    }
   ],
   "source": [
    "# System/env config\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "parent_dir = Path.cwd().resolve().parent\n",
    "sys.path.append(str(parent_dir))\n",
    "print('Current dir for import:', parent_dir)\n",
    "\n",
    "from src.config import Config\n",
    "config = Config()\n",
    "print('Config initialized')\n",
    "\n",
    "\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Modules for data \n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Any\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from datasets import Dataset\n",
    "from datasets import load_from_disk\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoConfig, AutoModelForSequenceClassification,\n",
    "    TrainingArguments, Trainer, EarlyStoppingCallback\n",
    ")\n",
    "\n",
    "import evaluate\n",
    "import torch\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import CRF\n",
    "from seqeval.metrics import f1_score, precision_score, recall_score, classification_report\n",
    "from seqeval.scheme import IOB2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cdc34c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"jjzha/skillspan\", cache_dir=config['raw_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0af079ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['idx', 'tokens', 'tags_skill', 'tags_knowledge', 'source'],\n",
       "        num_rows: 4800\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['idx', 'tokens', 'tags_skill', 'tags_knowledge', 'source'],\n",
       "        num_rows: 3174\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['idx', 'tokens', 'tags_skill', 'tags_knowledge', 'source'],\n",
       "        num_rows: 3569\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127327c5",
   "metadata": {},
   "source": [
    "### Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bfc3635",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = ds['train'].select_columns(['tokens', 'tags_skill']).to_pandas()\n",
    "df_validation = ds['validation'].select_columns(['tokens', 'tags_skill']).to_pandas()\n",
    "df_test = ds['test'].select_columns(['tokens', 'tags_skill']).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dae98ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>tags_skill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Senior, QA, Engineer, (, m/f/d, ), &lt;ORGANIZAT...</td>\n",
       "      <td>[O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[&lt;ADDRESS&gt;, &lt;ADDRESS&gt;, &lt;ADDRESS&gt;, &lt;ADDRESS&gt;, &lt;...</td>\n",
       "      <td>[O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Date, posted:, 2021-07-14]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Likes:, 0, Dislikes:, 0, Love:, 0]</td>\n",
       "      <td>[O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Job, description:]</td>\n",
       "      <td>[O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4795</th>\n",
       "      <td>[Furthermore, we, expect, you, to, be, able, t...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, B, I, I, I, I, I, I, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4796</th>\n",
       "      <td>[You, are, structured, and, proactive, and, yo...</td>\n",
       "      <td>[O, O, B, O, B, O, O, O, O, B, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4797</th>\n",
       "      <td>[You, are, a, holistic, and, fact, based, prag...</td>\n",
       "      <td>[O, O, O, B, O, B, I, B, B, I, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4798</th>\n",
       "      <td>[Last, but, not, least, you, both, have, the, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, B, I, I, I, I, I, I, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4799</th>\n",
       "      <td>[Fluency, in, written, and, spoken, English, i...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tokens  \\\n",
       "0     [Senior, QA, Engineer, (, m/f/d, ), <ORGANIZAT...   \n",
       "1     [<ADDRESS>, <ADDRESS>, <ADDRESS>, <ADDRESS>, <...   \n",
       "2                           [Date, posted:, 2021-07-14]   \n",
       "3                   [Likes:, 0, Dislikes:, 0, Love:, 0]   \n",
       "4                                   [Job, description:]   \n",
       "...                                                 ...   \n",
       "4795  [Furthermore, we, expect, you, to, be, able, t...   \n",
       "4796  [You, are, structured, and, proactive, and, yo...   \n",
       "4797  [You, are, a, holistic, and, fact, based, prag...   \n",
       "4798  [Last, but, not, least, you, both, have, the, ...   \n",
       "4799  [Fluency, in, written, and, spoken, English, i...   \n",
       "\n",
       "                                             tags_skill  \n",
       "0                                 [O, O, O, O, O, O, O]  \n",
       "1                                       [O, O, O, O, O]  \n",
       "2                                             [O, O, O]  \n",
       "3                                    [O, O, O, O, O, O]  \n",
       "4                                                [O, O]  \n",
       "...                                                 ...  \n",
       "4795  [O, O, O, O, O, O, O, O, B, I, I, I, I, I, I, ...  \n",
       "4796  [O, O, B, O, B, O, O, O, O, B, O, O, O, O, O, ...  \n",
       "4797  [O, O, O, B, O, B, I, B, B, I, O, O, O, O, O, ...  \n",
       "4798  [O, O, O, O, O, O, O, O, B, I, I, I, I, I, I, ...  \n",
       "4799            [O, O, O, O, O, O, O, O, O, O, O, O, O]  \n",
       "\n",
       "[4800 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55894d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4800 entries, 0 to 4799\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   tokens      4800 non-null   object\n",
      " 1   tags_skill  4800 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 75.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a4e95c",
   "metadata": {},
   "source": [
    "Protoryping output CoNLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "311cc8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tokens, tags in zip(df_train[\"tokens\"], df_train[\"tags_skill\"]):\n",
    "#     for t, y in zip(tokens, tags):\n",
    "#         print(f\"{t}\\t{y}\")\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef2ad690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of skipped rows: 0\n",
      "Number of skipped rows: 0\n",
      "Invalid BIO sequence: ['O', 'O', 'O', 'O', 'O', 'O', 'I-SKILL', 'I-SKILL', 'I-SKILL']\n",
      "\t\t\tLine: ['Experience', 'with', 'agile', 'approaches', 'to', 'software', 'testing', 'and', 'development']\n",
      "This line will be skipped\n",
      "Number of skipped rows: 1\n",
      "Done. CoNLL files saved to: C:\\Users\\Мариан\\Desktop\\Jupyter Notes\\Projects\\Trainee_iFortex\\Git\\job_posting\\data\\03_validated\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Prepare CoNLL files using only the 'tags_skill' column.\n",
    "# All comments are in English.\n",
    "def normalize_bio_tags(tags, label=\"SKILL\"):\n",
    "    \"\"\"Convert bare BIO like ['O','B','I',...] into typed BIO like ['O','B-SKILL','I-SKILL',...].\"\"\"\n",
    "    out = []\n",
    "    for t in tags:\n",
    "        if t == \"O\":\n",
    "            out.append(\"O\")\n",
    "        elif t == \"B\":\n",
    "            out.append(f\"B-{label}\")\n",
    "        elif t == \"I\":\n",
    "            out.append(f\"I-{label}\")\n",
    "        else:\n",
    "            # already typed or unexpected; keep as is\n",
    "            out.append(t)\n",
    "    return out\n",
    "\n",
    "def validate_bio_sequence(tags):\n",
    "    \"\"\"\n",
    "    Quick BIO validator: 'I-X' must follow 'B-X' or 'I-X' of the same type.\n",
    "    Returns True if valid.\n",
    "    \"\"\"\n",
    "    prev_type = None\n",
    "    prev_tag = \"O\"\n",
    "    for t in tags:\n",
    "        if t == \"O\":\n",
    "            prev_tag, prev_type = \"O\", None\n",
    "            continue\n",
    "        m = re.match(r\"([BI])-(.+)\", t)\n",
    "        if not m:\n",
    "            return False\n",
    "        bi, lab = m.groups()\n",
    "        if bi == \"B\":\n",
    "            prev_tag, prev_type = \"B\", lab\n",
    "        else:  # I\n",
    "            if prev_tag == \"O\" or prev_type != lab:\n",
    "                return False\n",
    "            prev_tag = \"I\"\n",
    "    return True\n",
    "\n",
    "def write_conll_from_df(df: pd.DataFrame, tokens_col=\"tokens\", tags_col=\"tags_skill\", out_path: Path = Path(\"train.conll\")):\n",
    "    \"\"\"\n",
    "    Write a classic CoNLL file with two columns: token<TAB>label.\n",
    "    Assumes each row has a list of tokens and a same-length list of BIO tags.\n",
    "    \"\"\"\n",
    "    skipped = 0\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with out_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        for _, row in df.iterrows():\n",
    "            tokens = list(row[tokens_col])\n",
    "            tags   = list(row[tags_col])\n",
    "            assert len(tokens) == len(tags), \"Tokens and tags length mismatch\"\n",
    "            if not validate_bio_sequence(tags):\n",
    "                print(f\"Invalid BIO sequence: {tags}\\n\\t\\t\\tLine: {tokens}\")\n",
    "                print('This line will be skipped')\n",
    "                skipped += 1\n",
    "                continue\n",
    "            for t, y in zip(tokens, tags):\n",
    "                f.write(f\"{t}\\t{y}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "    print(f'Number of skipped rows: {skipped}')\n",
    "\n",
    "# === Usage example ===\n",
    "# Suppose you already loaded df_train, df_dev, df_test with columns: \n",
    "#   [\"idx\", \"tokens\", \"tags_skill\", \"tags_knowledge\", \"source\"]\n",
    "\n",
    "for df in (df_train, df_validation, df_test):\n",
    "    df[\"tags_skill\"] = df[\"tags_skill\"].apply(lambda lst: normalize_bio_tags(lst, label=\"SKILL\"))\n",
    "\n",
    "out_dir = config['validated_dir']\n",
    "write_conll_from_df(df_train,      out_path=out_dir / \"train.conll\"     )\n",
    "write_conll_from_df(df_validation, out_path=out_dir / \"validation.conll\")\n",
    "write_conll_from_df(df_test,       out_path=out_dir / \"test.conll\"      )\n",
    "\n",
    "print(\"Done. CoNLL files saved to:\", out_dir.resolve())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a04c457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Single-file pipeline: CoNLL -> CRF baseline -> BERT token classification (BIO/IOB)\n",
    "# # Requires: pip install sklearn-crfsuite seqeval transformers datasets torch joblib\n",
    "\n",
    "# import os, re, json, random, sys\n",
    "# from pathlib import Path\n",
    "# from typing import List, Tuple, Dict, Any\n",
    "# import joblib\n",
    "\n",
    "# # ---------- CoNLL reader ----------\n",
    "# def read_conll(path: Path) -> Tuple[List[List[str]], List[List[str]]]:\n",
    "#     \"\"\"Read two-column CoNLL (token[TAB]label), blank line separates sentences.\n",
    "#     Returns tokens_list, labels_list where tokens_list[i] aligns to labels_list[i].\"\"\"\n",
    "#     tokens_list, labels_list = [], []\n",
    "#     cur_tokens, cur_labels = [], []\n",
    "#     with path.open(encoding=\"utf-8\") as f:\n",
    "#         for line in f:\n",
    "#             line = line.rstrip(\"\\n\")\n",
    "#             if not line:\n",
    "#                 if cur_tokens:\n",
    "#                     tokens_list.append(cur_tokens); labels_list.append(cur_labels)\n",
    "#                     cur_tokens, cur_labels = [], []\n",
    "#                 continue\n",
    "#             parts = line.split(\"\\t\")\n",
    "#             if len(parts) != 2:\n",
    "#                 raise ValueError(f\"Expected 2 columns token<TAB>label, got: {line}\")\n",
    "#             tok, lab = parts\n",
    "#             cur_tokens.append(tok); cur_labels.append(lab)\n",
    "#     if cur_tokens:\n",
    "#         tokens_list.append(cur_tokens); labels_list.append(cur_labels)\n",
    "#     return tokens_list, labels_list\n",
    "\n",
    "# # ---------- Simple BIO features for CRF ----------\n",
    "# def word2features(sent: List[str], i: int) -> Dict[str, Any]:\n",
    "#     \"\"\"Hand-crafted token features for CRF.\"\"\"\n",
    "#     w = sent[i]\n",
    "#     prevw = sent[i-1] if i > 0 else \"__BOS__\"\n",
    "#     nextw = sent[i+1] if i < len(sent)-1 else \"__EOS__\"\n",
    "#     feats = {\n",
    "#         \"bias\": 1.0,\n",
    "#         \"w.lower\": w.lower(),\n",
    "#         \"w.isupper\": w.isupper(),\n",
    "#         \"w.istitle\": w.istitle(),\n",
    "#         \"w.isdigit\": w.isdigit(),\n",
    "#         \"suffix3\": w[-3:],\n",
    "#         \"suffix2\": w[-2:],\n",
    "#         \"prefix2\": w[:2],\n",
    "#         \"prev.lower\": prevw.lower(),\n",
    "#         \"prev.istitle\": prevw.istitle() if prevw not in (\"__BOS__\",\"__EOS__\") else False,\n",
    "#         \"prev.isupper\": prevw.isupper() if prevw not in (\"__BOS__\",\"__EOS__\") else False,\n",
    "#         \"next.lower\": nextw.lower(),\n",
    "#         \"next.istitle\": nextw.istitle() if nextw not in (\"__BOS__\",\"__EOS__\") else False,\n",
    "#         \"next.isupper\": nextw.isupper() if nextw not in (\"__BOS__\",\"__EOS__\") else False,\n",
    "#         \"BOS\": i == 0,\n",
    "#         \"EOS\": i == len(sent)-1,\n",
    "#     }\n",
    "#     return feats\n",
    "\n",
    "# def sent2features(sent: List[str]) -> List[Dict[str, Any]]:\n",
    "#     return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "# # ---------- Span-F1 via seqeval ----------\n",
    "# from seqeval.metrics import f1_score, precision_score, recall_score, classification_report\n",
    "\n",
    "# def print_seqeval_report(y_true: List[List[str]], y_pred: List[List[str]], title: str):\n",
    "#     print(f\"\\n=== {title} ===\")\n",
    "#     print(\"Precision:\", round(precision_score(y_true, y_pred), 4))\n",
    "#     print(\"Recall   :\", round(recall_score(y_true, y_pred), 4))\n",
    "#     print(\"F1       :\", round(f1_score(y_true, y_pred), 4))\n",
    "#     print(classification_report(y_true, y_pred, digits=4))\n",
    "\n",
    "# # ---------- CRF baseline ----------\n",
    "# def run_crf(train_sents, train_labels, dev_sents, dev_labels, test_sents, test_labels, model_path: Path):\n",
    "#     from sklearn_crfsuite import CRF\n",
    "#     X_train = [sent2features(s) for s in train_sents]\n",
    "#     X_dev   = [sent2features(s) for s in dev_sents]\n",
    "#     X_test  = [sent2features(s) for s in test_sents]\n",
    "#     y_train = train_labels\n",
    "#     y_dev   = dev_labels\n",
    "#     y_test  = test_labels\n",
    "\n",
    "#     crf = CRF(algorithm=\"lbfgs\", c1=0.1, c2=0.1, max_iterations=200, all_possible_transitions=True)\n",
    "#     crf.fit(X_train, y_train)\n",
    "#     y_dev_pred  = crf.predict(X_dev)\n",
    "#     y_test_pred = crf.predict(X_test)\n",
    "\n",
    "#     print_seqeval_report(y_dev, y_dev_pred, \"CRF DEV\")\n",
    "#     print_seqeval_report(y_test, y_test_pred, \"CRF TEST\")\n",
    "\n",
    "#     model_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "#     joblib.dump(crf, model_path)\n",
    "#     print(f\"CRF model saved to: {model_path.resolve()}\")\n",
    "\n",
    "# # ---------- BERT token-classification ----------\n",
    "# def run_bert(\n",
    "#     train_sents, train_labels, dev_sents, dev_labels, test_sents, test_labels,\n",
    "#     out_dir: Path, bert_ckpt: str = \"bert-base-cased\", epochs: int = 3, batch_size: int = 16, lr: float = 5e-5\n",
    "# ):\n",
    "#     from transformers import AutoTokenizer, AutoModelForTokenClassification, DataCollatorForTokenClassification, Trainer, TrainingArguments\n",
    "#     import torch\n",
    "#     from datasets import Dataset, DatasetDict\n",
    "\n",
    "#     # Collect label set preserving BIO strings\n",
    "#     label_list = sorted({lab for seq in (train_labels + dev_labels + test_labels) for lab in seq})\n",
    "#     if any(lab not in {\"O\"} and not re.match(r\"^[BI]-\", lab) for lab in label_list):\n",
    "#         raise ValueError(f\"Labels look non-BIO: {label_list}\")\n",
    "\n",
    "#     label2id = {lab: i for i, lab in enumerate(label_list)}\n",
    "#     id2label = {i: lab for lab, i in label2id.items()}\n",
    "\n",
    "#     # Build HF datasets\n",
    "#     def to_rows(sents: List[List[str]], labels: List[List[str]]) -> Dict[str, List[Any]]:\n",
    "#         return {\"tokens\": sents, \"ner_tags\": [[label2id[l] for l in seq] for seq in labels]}\n",
    "\n",
    "#     d_train = Dataset.from_dict(to_rows(train_sents, train_labels))\n",
    "#     d_dev   = Dataset.from_dict(to_rows(dev_sents,   dev_labels))\n",
    "#     d_test  = Dataset.from_dict(to_rows(test_sents,  test_labels))\n",
    "#     ds = DatasetDict({\"train\": d_train, \"validation\": d_dev, \"test\": d_test})\n",
    "\n",
    "#     tokenizer = AutoTokenizer.from_pretrained(bert_ckpt, use_fast=True)\n",
    "\n",
    "#     # Align labels to wordpieces: keep label for first subword, set -100 for others\n",
    "#     def tokenize_and_align(example: Dict[str, Any]) -> Dict[str, Any]:\n",
    "#         toks = example[\"tokens\"]\n",
    "#         labs = example[\"ner_tags\"]\n",
    "#         enc = tokenizer(toks, is_split_into_words=True, truncation=True)\n",
    "#         word_ids = enc.word_ids()\n",
    "#         aligned = []\n",
    "#         prev_word = None\n",
    "#         for idx, wid in enumerate(word_ids):\n",
    "#             if wid is None:\n",
    "#                 aligned.append(-100)\n",
    "#             elif wid != prev_word:\n",
    "#                 aligned.append(labs[wid])\n",
    "#             else:\n",
    "#                 aligned.append(-100)\n",
    "#             prev_word = wid\n",
    "#         enc[\"labels\"] = aligned\n",
    "#         return enc\n",
    "\n",
    "#     ds_tok = ds.map(tokenize_and_align, batched=False)\n",
    "\n",
    "#     model = AutoModelForTokenClassification.from_pretrained(\n",
    "#         bert_ckpt,\n",
    "#         num_labels=len(label_list),\n",
    "#         id2label=id2label,\n",
    "#         label2id=label2id\n",
    "#     )\n",
    "\n",
    "#     data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "\n",
    "#     def compute_metrics(p):\n",
    "#         preds = p.predictions\n",
    "#         if isinstance(preds, tuple):\n",
    "#             preds = preds[0]\n",
    "#         preds = preds.argmax(-1)\n",
    "#         labels = p.label_ids\n",
    "#         # Unpack to BIO strings, skipping -100\n",
    "#         true_str, pred_str = [], []\n",
    "#         for y_true, y_pred in zip(labels, preds):\n",
    "#             y_true_seq, y_pred_seq = [], []\n",
    "#             for t, p_ in zip(y_true, y_pred):\n",
    "#                 if t == -100:\n",
    "#                     continue\n",
    "#                 y_true_seq.append(id2label[int(t)])\n",
    "#                 y_pred_seq.append(id2label[int(p_)])\n",
    "#             true_str.append(y_true_seq)\n",
    "#             pred_str.append(y_pred_seq)\n",
    "#         return {\n",
    "#             \"precision\": precision_score(true_str, pred_str),\n",
    "#             \"recall\":    recall_score(true_str, pred_str),\n",
    "#             \"f1\":        f1_score(true_str, pred_str),\n",
    "#         }\n",
    "\n",
    "#     out_dir.mkdir(parents=True, exist_ok=True)\n",
    "#     args = TrainingArguments(\n",
    "#         output_dir=str(out_dir),\n",
    "#         evaluation_strategy=\"epoch\",\n",
    "#         save_strategy=\"epoch\",\n",
    "#         learning_rate=lr,\n",
    "#         per_device_train_batch_size=batch_size,\n",
    "#         per_device_eval_batch_size=batch_size,\n",
    "#         num_train_epochs=epochs,\n",
    "#         weight_decay=0.01,\n",
    "#         logging_steps=50,\n",
    "#         load_best_model_at_end=True,\n",
    "#         metric_for_best_model=\"f1\",\n",
    "#         report_to=\"none\"\n",
    "#     )\n",
    "\n",
    "#     trainer = Trainer(\n",
    "#         model=model,\n",
    "#         args=args,\n",
    "#         train_dataset=ds_tok[\"train\"],\n",
    "#         eval_dataset=ds_tok[\"validation\"],\n",
    "#         tokenizer=tokenizer,\n",
    "#         data_collator=data_collator,\n",
    "#         compute_metrics=compute_metrics\n",
    "#     )\n",
    "\n",
    "#     trainer.train()\n",
    "#     print(\"\\n=== BERT DEV ===\")\n",
    "#     dev_metrics = trainer.evaluate()\n",
    "#     print({k: round(float(v), 4) for k, v in dev_metrics.items() if k in (\"precision\",\"recall\",\"f1\")})\n",
    "\n",
    "#     print(\"\\n=== BERT TEST ===\")\n",
    "#     test_metrics = trainer.evaluate(ds_tok[\"test\"])\n",
    "#     print({k: round(float(v), 4) for k, v in test_metrics.items() if k in (\"precision\",\"recall\",\"f1\")})\n",
    "\n",
    "#     save_path = out_dir / \"final\"\n",
    "#     trainer.save_model(str(save_path))\n",
    "#     tokenizer.save_pretrained(str(save_path))\n",
    "#     with (out_dir / \"label_mapping.json\").open(\"w\", encoding=\"utf-8\") as f:\n",
    "#         json.dump({\"label_list\": label_list, \"label2id\": label2id}, f, ensure_ascii=False, indent=2)\n",
    "#     print(f\"BERT model saved to: {save_path.resolve()}\")\n",
    "\n",
    "# # ---------- Entry point ----------\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Configure paths and model\n",
    "#     data_dir = Path(os.environ.get(\"CONLL_DIR\", \"conll_only_skill\"))  # folder with train.conll, validation.conll, test.conll\n",
    "#     train_path = data_dir / \"train.conll\"\n",
    "#     dev_path   = data_dir / \"validation.conll\"\n",
    "#     test_path  = data_dir / \"test.conll\"\n",
    "#     bert_ckpt  = os.environ.get(\"BERT_CKPT\", \"bert-base-cased\")\n",
    "#     out_dir    = Path(os.environ.get(\"BERT_OUT\", \"bert_skill_ner\"))\n",
    "#     random.seed(13)\n",
    "\n",
    "#     train_sents, train_labels = read_conll(train_path)\n",
    "#     dev_sents,   dev_labels   = read_conll(dev_path)\n",
    "#     test_sents,  test_labels  = read_conll(test_path)\n",
    "\n",
    "#     # Quick sanity checks\n",
    "#     assert all(len(s) == len(l) for s, l in zip(train_sents, train_labels)), \"Train tokens/labels len mismatch\"\n",
    "#     assert all(re.match(r\"^(O|[BI]-.+)$\", lab) for seq in train_labels for lab in seq), \"Non-BIO label in train\"\n",
    "\n",
    "#     # CRF baseline\n",
    "#     run_crf(\n",
    "#         train_sents, train_labels,\n",
    "#         dev_sents,   dev_labels,\n",
    "#         test_sents,  test_labels,\n",
    "#         model_path=Path(\"crf_model.joblib\")\n",
    "#     )\n",
    "\n",
    "#     # BERT fine-tuning\n",
    "#     run_bert(\n",
    "#         train_sents, train_labels,\n",
    "#         dev_sents,   dev_labels,\n",
    "#         test_sents,  test_labels,\n",
    "#         out_dir=out_dir,\n",
    "#         bert_ckpt=bert_ckpt,\n",
    "#         epochs=3,\n",
    "#         batch_size=16,\n",
    "#         lr=5e-5\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "245ab068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#train sents: 4800  #val: 3174  #test: 3568\n"
     ]
    }
   ],
   "source": [
    "# === 1) Data loading (CoNLL -> lists of sentences) ===\n",
    "def read_conll(path: Path) -> tuple[list[list[str]], list[list[str]]]:\n",
    "    \"\"\"\n",
    "    Read a two-column CoNLL file (token<TAB>tag>), sentences separated by blank lines.\n",
    "    Returns: tokens_per_sent, tags_per_sent as lists of lists.\n",
    "    \"\"\"\n",
    "    s_tokens, s_tags = [], []\n",
    "    tokens, tags = [], []\n",
    "    with path.open(encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.rstrip(\"\\n\")\n",
    "            if not line:\n",
    "                if tokens:\n",
    "                    s_tokens.append(tokens)\n",
    "                    s_tags.append(tags)\n",
    "                    tokens, tags = [], []\n",
    "                continue\n",
    "            parts = line.split(\"\\t\")\n",
    "            if len(parts) != 2:\n",
    "                # Skip malformed lines safely\n",
    "                continue\n",
    "            tok, lab = parts\n",
    "            tokens.append(tok)\n",
    "            tags.append(lab)\n",
    "    if tokens:\n",
    "        s_tokens.append(tokens)\n",
    "        s_tags.append(tags)\n",
    "    return s_tokens, s_tags\n",
    "\n",
    "\n",
    "\n",
    "X_tokens_train, y_train = read_conll(config['train_connl'])\n",
    "X_tokens_val,   y_val   = read_conll(config['validation_connl'])\n",
    "X_tokens_test,  y_test  = read_conll(config['test_connl'])\n",
    "\n",
    "\n",
    "print(f\"#train sents: {len(X_tokens_train)}  #val: {len(X_tokens_val)}  #test: {len(X_tokens_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f0be0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2184, 5944)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_skill_gazetteers(tokens_per_sent: list[list[str]], tags_per_sent: list[list[str]]) -> dict[str, set[str]]:\n",
    "    \"\"\"\n",
    "    Build simple gazetteers from training data:\n",
    "      - skill_unigrams: lowercased tokens appearing inside any SKILL span\n",
    "      - skill_bigrams:  lowercased bigrams inside SKILL spans\n",
    "    \"\"\"\n",
    "    skill_unigrams = set()\n",
    "    skill_bigrams  = set()\n",
    "    for toks, labs in zip(tokens_per_sent, tags_per_sent):\n",
    "        # collect indices of tokens inside SKILL spans (B-SKILL / I-SKILL)\n",
    "        inside = [i for i, t in enumerate(labs) if t.startswith(\"B-\") or t.startswith(\"I-\")]\n",
    "        for i in inside:\n",
    "            skill_unigrams.add(toks[i].lower())\n",
    "        # bigrams (consecutive tokens both inside a span)\n",
    "        for i in range(len(toks) - 1):\n",
    "            if (labs[i].startswith((\"B-\",\"I-\"))) and (labs[i+1].startswith((\"B-\",\"I-\"))):\n",
    "                skill_bigrams.add((toks[i].lower(), toks[i+1].lower()))\n",
    "    return {\"skill_unigrams\": skill_unigrams, \"skill_bigrams\": skill_bigrams}\n",
    "\n",
    "gazetteers = build_skill_gazetteers(X_tokens_train, y_train)\n",
    "len(gazetteers[\"skill_unigrams\"]), len(gazetteers[\"skill_bigrams\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a13f2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 400)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def char_ngrams(token: str, n: int) -> list[str]:\n",
    "    token = token\n",
    "    return [token[i:i+n] for i in range(len(token) - n + 1)] if len(token) >= n else []\n",
    "\n",
    "def top_char_ngrams(tokens_per_sent: list[list[str]], top_k: int = 400) -> dict[str, set[str]]:\n",
    "    \"\"\"\n",
    "    Compute most frequent char 2-grams and 3-grams from TRAIN tokens only and keep top_k for each size.\n",
    "    This caps feature explosion while still giving CRF helpful subword signals.\n",
    "    \"\"\"\n",
    "    c2 = Counter()\n",
    "    c3 = Counter()\n",
    "    for sent in tokens_per_sent:\n",
    "        for tok in sent:\n",
    "            c2.update(char_ngrams(tok, 2))\n",
    "            c3.update(char_ngrams(tok, 3))\n",
    "    top2 = set([ng for ng, _ in c2.most_common(top_k)])\n",
    "    top3 = set([ng for ng, _ in c3.most_common(top_k)])\n",
    "    return {\"char2\": top2, \"char3\": top3}\n",
    "\n",
    "char_ngram_vocab = top_char_ngrams(X_tokens_train, top_k=400)\n",
    "len(char_ngram_vocab[\"char2\"]), len(char_ngram_vocab[\"char3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "347e8c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREF_SIZES = (2, 3, 4)\n",
    "SUFF_SIZES = (2, 3, 4)\n",
    "\n",
    "def word_shape(token: str) -> str:\n",
    "    \"\"\"\n",
    "    Map token to a coarse 'shape' (e.g., 'Xx', 'xxx', 'd-dd', 'xxx-xx', 'Xx.' etc.).\n",
    "    Helps generalize across casing/digits/punct.\n",
    "    \"\"\"\n",
    "    shape = []\n",
    "    for ch in token:\n",
    "        if ch.isupper():\n",
    "            shape.append('X')\n",
    "        elif ch.islower():\n",
    "            shape.append('x')\n",
    "        elif ch.isdigit():\n",
    "            shape.append('d')\n",
    "        elif ch in \"-_/\\\\.\":\n",
    "            shape.append(ch)\n",
    "        else:\n",
    "            shape.append('p')  # other punct\n",
    "    # collapse runs like XXX -> X, xxx -> x to reduce sparsity\n",
    "    collapsed = []\n",
    "    for ch in shape:\n",
    "        if not collapsed or collapsed[-1] != ch:\n",
    "            collapsed.append(ch)\n",
    "    return ''.join(collapsed)\n",
    "\n",
    "def token_features(sent: list[str], i: int,\n",
    "                   gaz: dict[str, set[str]],\n",
    "                   char_vocab: dict[str, set[str]]) -> dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Build a feature dict for token sent[i].\n",
    "    Includes:\n",
    "      - bias, word lowercase, shape, isupper/istitle/isdigit/has_digit/has_hyphen\n",
    "      - prefixes/suffixes, limited char 2/3-grams (only if in top lists)\n",
    "      - simple gazetteers (unigram + adjacent bigrams), plus +/-1 and +/-2 window features\n",
    "    \"\"\"\n",
    "    token = sent[i]\n",
    "    lower = token.lower()\n",
    "    feats = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower': lower,\n",
    "        'word.shape': word_shape(token),\n",
    "        'word.isupper': token.isupper(),\n",
    "        'word.istitle': token.istitle(),\n",
    "        'word.isdigit': token.isdigit(),\n",
    "        'word.has_digit': any(ch.isdigit() for ch in token),\n",
    "        'word.has_hyphen': '-' in token,\n",
    "        'word.has_dot': '.' in token,\n",
    "        'word.has_slash': '/' in token or '\\\\' in token,\n",
    "        'gaz.in_skill_unigram': (lower in gaz['skill_unigrams']),\n",
    "    }\n",
    "    # prefixes / suffixes\n",
    "    for n in PREF_SIZES:\n",
    "        feats[f'pref{n}'] = lower[:n] if len(lower) >= n else lower\n",
    "    for n in SUFF_SIZES:\n",
    "        feats[f'suff{n}'] = lower[-n:] if len(lower) >= n else lower\n",
    "\n",
    "    # limited char 2/3-grams (only those that are in top vocab to control dimensionality)\n",
    "    for ng in char_ngrams(token, 2):\n",
    "        if ng in char_vocab['char2']:\n",
    "            feats[f'char2={ng}'] = True\n",
    "    for ng in char_ngrams(token, 3):\n",
    "        if ng in char_vocab['char3']:\n",
    "            feats[f'char3={ng}'] = True\n",
    "\n",
    "    # context features (+/- 1, +/- 2)\n",
    "    def add_ctx(j: int, tag: str):\n",
    "        if 0 <= j < len(sent):\n",
    "            w = sent[j]\n",
    "            lw = w.lower()\n",
    "            feats[f'{tag}.lower'] = lw\n",
    "            feats[f'{tag}.shape'] = word_shape(w)\n",
    "            feats[f'{tag}.istitle'] = w.istitle()\n",
    "            feats[f'{tag}.isupper'] = w.isupper()\n",
    "\n",
    "    add_ctx(i-1, '-1')\n",
    "    add_ctx(i-2, '-2')\n",
    "    add_ctx(i+1, '+1')\n",
    "    add_ctx(i+2, '+2')\n",
    "\n",
    "    # gazetteer bigrams with neighbors (prev+cur, cur+next)\n",
    "    if i-1 >= 0:\n",
    "        feats['gaz.prev_cur_in_skill_bigram'] = (sent[i-1].lower(), lower) in gaz['skill_bigrams']\n",
    "    if i+1 < len(sent):\n",
    "        feats['gaz.cur_next_in_skill_bigram'] = (lower, sent[i+1].lower()) in gaz['skill_bigrams']\n",
    "\n",
    "    return feats\n",
    "\n",
    "def sent2features(sent: list[str],\n",
    "                  gaz: dict[str, set[str]],\n",
    "                  char_vocab: dict[str, set[str]]) -> list[dict[str, Any]]:\n",
    "    return [token_features(sent, i, gaz, char_vocab) for i in range(len(sent))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd8b048f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800 4800 3174 3174\n",
      "7 7 {'bias': 1.0, 'word.lower': 'senior', 'word.shape': 'Xx', 'word.isupper': False, 'word.istitle': True, 'word.isdigit': False, 'word.has_digit': False, 'word.has_hyphen': False, 'word.has_dot': False, 'word.has_slash': False, 'gaz.in_skill_unigram': True, 'pref2': 'se', 'pref3': 'sen', 'pref4': 'seni', 'suff2': 'or', 'suff3': 'ior', 'suff4': 'nior', 'char2=Se': True, 'char2=en': True, 'char2=ni': True, 'char2=io': True, 'char2=or': True, '+1.lower': 'qa', '+1.shape': 'X', '+1.istitle': False, '+1.isupper': True, '+2.lower': 'engineer', '+2.shape': 'Xx', '+2.istitle': True, '+2.isupper': False, 'gaz.cur_next_in_skill_bigram': False}\n"
     ]
    }
   ],
   "source": [
    "def to_crf_Xy(tokens_per_sent: list[list[str]],\n",
    "              tags_per_sent: list[list[str]],\n",
    "              gaz: dict[str, set[str]],\n",
    "              char_vocab: dict[str, set[str]]):\n",
    "    X = [sent2features(s, gaz, char_vocab) for s in tokens_per_sent]\n",
    "    y = [list(tags) for tags in tags_per_sent]\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train_ = to_crf_Xy(X_tokens_train, y_train, gazetteers, char_ngram_vocab)\n",
    "X_val_,  y_val_   = to_crf_Xy(X_tokens_val,   y_val,   gazetteers, char_ngram_vocab)\n",
    "X_test_, y_test_  = to_crf_Xy(X_tokens_test,  y_test,  gazetteers, char_ngram_vocab)\n",
    "\n",
    "# Quick sanity check\n",
    "print(len(X_train), len(y_train_), len(X_val_), len(y_val_))\n",
    "print(len(X_train[0]), len(y_train_[0]), X_train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed900a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRF trained.\n"
     ]
    }
   ],
   "source": [
    "crf = CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,               # L1\n",
    "    c2=0.1,               # L2\n",
    "    max_iterations=200,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "\n",
    "crf.fit(X_train, y_train_)\n",
    "print(\"CRF trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c04f1cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Val [oracle sanity] (span-level) ===\n",
      "Precision: 1.0000  Recall: 1.0000  F1: 1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       SKILL     1.0000    1.0000    1.0000      1070\n",
      "\n",
      "   micro avg     1.0000    1.0000    1.0000      1070\n",
      "   macro avg     1.0000    1.0000    1.0000      1070\n",
      "weighted avg     1.0000    1.0000    1.0000      1070\n",
      "\n",
      "=== Val (span-level) ===\n",
      "Precision: 0.3375  Recall: 0.1000  F1: 0.1543\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       SKILL     0.3375    0.1000    0.1543      1070\n",
      "\n",
      "   micro avg     0.3375    0.1000    0.1543      1070\n",
      "   macro avg     0.3375    0.1000    0.1543      1070\n",
      "weighted avg     0.3375    0.1000    0.1543      1070\n",
      "\n",
      "=== Test (span-level) ===\n",
      "Precision: 0.3607  Recall: 0.1009  F1: 0.1577\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       SKILL     0.3607    0.1009    0.1577      1090\n",
      "\n",
      "   micro avg     0.3607    0.1009    0.1577      1090\n",
      "   macro avg     0.3607    0.1009    0.1577      1090\n",
      "weighted avg     0.3607    0.1009    0.1577      1090\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def eval_seqeval(y_true, y_pred, title: str = \"Eval\"):\n",
    "    print(f\"=== {title} (span-level) ===\")\n",
    "    p = precision_score(y_true, y_pred, scheme=IOB2)\n",
    "    r = recall_score(y_true, y_pred, scheme=IOB2)\n",
    "    f = f1_score(y_true, y_pred, scheme=IOB2)\n",
    "    print(f\"Precision: {p:.4f}  Recall: {r:.4f}  F1: {f:.4f}\")\n",
    "    print(classification_report(y_true, y_pred, scheme=IOB2, digits=4))\n",
    "\n",
    "y_val_pred  = crf.predict(X_val_)\n",
    "y_test_pred = crf.predict(X_test_)\n",
    "\n",
    "eval_seqeval(y_val_,  y_val_,  title=\"Val [oracle sanity]\")     # sanity: should be 1.0\n",
    "eval_seqeval(y_val_,  y_val_pred,  title=\"Val\")\n",
    "eval_seqeval(y_test_, y_test_pred, title=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebfcc66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "job-posting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
